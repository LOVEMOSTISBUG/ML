{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0495bae0-fbd3-4dcc-bb6d-d31c36da394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292022a1-4a45-47e7-ad5c-93f938d45ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_student</th>\n",
       "      <th>pretest</th>\n",
       "      <th>school_setting_Rural</th>\n",
       "      <th>school_setting_Suburban</th>\n",
       "      <th>school_setting_Urban</th>\n",
       "      <th>school_type_Non-public</th>\n",
       "      <th>school_type_Public</th>\n",
       "      <th>teaching_method_Experimental</th>\n",
       "      <th>teaching_method_Standard</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>lunch_Does not qualify</th>\n",
       "      <th>lunch_Qualifies for reduced/free lunch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>30.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_student  pretest  school_setting_Rural  school_setting_Suburban  \\\n",
       "0          20.0     62.0                     0                        0   \n",
       "1          20.0     66.0                     0                        0   \n",
       "2          20.0     64.0                     0                        0   \n",
       "3          20.0     61.0                     0                        0   \n",
       "4          20.0     64.0                     0                        0   \n",
       "...         ...      ...                   ...                      ...   \n",
       "2128       30.0     39.0                     0                        0   \n",
       "2129       30.0     38.0                     0                        0   \n",
       "2130       30.0     45.0                     0                        0   \n",
       "2131       30.0     46.0                     0                        0   \n",
       "2132       30.0     41.0                     0                        0   \n",
       "\n",
       "      school_setting_Urban  school_type_Non-public  school_type_Public  \\\n",
       "0                        1                       1                   0   \n",
       "1                        1                       1                   0   \n",
       "2                        1                       1                   0   \n",
       "3                        1                       1                   0   \n",
       "4                        1                       1                   0   \n",
       "...                    ...                     ...                 ...   \n",
       "2128                     1                       0                   1   \n",
       "2129                     1                       0                   1   \n",
       "2130                     1                       0                   1   \n",
       "2131                     1                       0                   1   \n",
       "2132                     1                       0                   1   \n",
       "\n",
       "      teaching_method_Experimental  teaching_method_Standard  gender_Female  \\\n",
       "0                                0                         1              1   \n",
       "1                                0                         1              1   \n",
       "2                                0                         1              0   \n",
       "3                                0                         1              1   \n",
       "4                                0                         1              0   \n",
       "...                            ...                       ...            ...   \n",
       "2128                             0                         1              1   \n",
       "2129                             0                         1              1   \n",
       "2130                             0                         1              1   \n",
       "2131                             0                         1              0   \n",
       "2132                             0                         1              0   \n",
       "\n",
       "      gender_Male  lunch_Does not qualify  \\\n",
       "0               0                       1   \n",
       "1               0                       1   \n",
       "2               1                       1   \n",
       "3               0                       1   \n",
       "4               1                       1   \n",
       "...           ...                     ...   \n",
       "2128            0                       1   \n",
       "2129            0                       0   \n",
       "2130            0                       0   \n",
       "2131            1                       0   \n",
       "2132            1                       0   \n",
       "\n",
       "      lunch_Qualifies for reduced/free lunch  \n",
       "0                                          0  \n",
       "1                                          0  \n",
       "2                                          0  \n",
       "3                                          0  \n",
       "4                                          0  \n",
       "...                                      ...  \n",
       "2128                                       0  \n",
       "2129                                       1  \n",
       "2130                                       1  \n",
       "2131                                       1  \n",
       "2132                                       1  \n",
       "\n",
       "[2133 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data = pd.read_csv(\"data_set/从11个特征预测学生的测试分数.csv\")\n",
    "X , Y = orig_data.iloc[:,0:10] , orig_data.iloc[:,-1] #切片\n",
    "X = X.drop(columns=[\"school\",\"classroom\",\"student_id\"],axis=1)#按列丢弃无关项\n",
    "X = pd.get_dummies(X,columns=[\"school_setting\",\"school_type\",\"teaching_method\",\"gender\",\"lunch\"],dtype=int)#独热编码 #orig_data.iloc[0:5,] X.iloc[0:5,]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71a365",
   "metadata": {},
   "source": [
    "一层神经网络模型  \n",
    "激活函数f(x)= x  \n",
    "损失函数均方误差  \n",
    "优化器Adam(默认比较优秀的优化器 结合了自适应梯度Adagrad和RMSProp防梯度急剧下降的优点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b907d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 996us/step - loss: 1433.4374\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 883us/step - loss: 124.9261\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 834us/step - loss: 53.3984\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 957us/step - loss: 48.3606\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 994us/step - loss: 43.5534\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 949us/step - loss: 38.9157\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 34.6806\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 30.9313\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 834us/step - loss: 27.6490\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 24.9015 - val_loss: 27.8869\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 950us/step - loss: 22.6165\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 20.7568\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 19.1724\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 17.9556\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 16.9600\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 16.1835\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 811us/step - loss: 15.5261\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 874us/step - loss: 14.9798\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 14.5842\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 14.2245 - val_loss: 13.0740\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 835us/step - loss: 13.9453\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 725us/step - loss: 13.6745\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 768us/step - loss: 13.4586\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 872us/step - loss: 13.3446\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 877us/step - loss: 13.1680\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 728us/step - loss: 12.9929\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 961us/step - loss: 12.9478\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 863us/step - loss: 12.8088\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 883us/step - loss: 12.7018\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.6147 - val_loss: 11.5293\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 12.5839\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 12.5183\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.4459\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 899us/step - loss: 12.3901\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 723us/step - loss: 12.3713\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 876us/step - loss: 12.3227\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 871us/step - loss: 12.2581\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 12.2581\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 728us/step - loss: 12.2595\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.1579 - val_loss: 11.5762\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 773us/step - loss: 12.1662\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 949us/step - loss: 12.1440\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 685us/step - loss: 12.1538\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 877us/step - loss: 12.1069\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 727us/step - loss: 12.0314\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 821us/step - loss: 12.0703\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 897us/step - loss: 12.0102\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 675us/step - loss: 11.9490\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 727us/step - loss: 11.9257\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.8984 - val_loss: 11.5807\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 919us/step - loss: 11.8986\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 720us/step - loss: 11.8903\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 724us/step - loss: 11.9000\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 964us/step - loss: 11.8355\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 756us/step - loss: 11.7954\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 872us/step - loss: 11.8137\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.7728\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 726us/step - loss: 11.7547\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 874us/step - loss: 11.6664\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.7220 - val_loss: 11.5635\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 810us/step - loss: 11.6629\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 836us/step - loss: 11.6073\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.6003\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 11.6233\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5297\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 993us/step - loss: 11.5125\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 725us/step - loss: 11.4525\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 708us/step - loss: 11.4797\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 843us/step - loss: 11.4291\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.4743 - val_loss: 11.4752\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 939us/step - loss: 11.4234\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 978us/step - loss: 11.4257\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 694us/step - loss: 11.3832\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 838us/step - loss: 11.3921\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 901us/step - loss: 11.3422\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 764us/step - loss: 11.2688\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 988us/step - loss: 11.2917\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 11.2719\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 798us/step - loss: 11.2477\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2319 - val_loss: 10.8535\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 659us/step - loss: 11.1927\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 723us/step - loss: 11.1694\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.3407\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2063\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3334\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 761us/step - loss: 11.2457\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 764us/step - loss: 11.1022\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.0742\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.0655\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9951 - val_loss: 10.5369\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 754us/step - loss: 11.0208\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 879us/step - loss: 11.0325\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 836us/step - loss: 10.9649\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 879us/step - loss: 11.0364\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.0419\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.0914\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.0185\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 722us/step - loss: 11.0383\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 774us/step - loss: 10.8504\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9911 - val_loss: 10.4819\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.13887373]\n",
      "pretest                                           [0.95360136]\n",
      "school_setting_Rural                                 [2.12488]\n",
      "school_setting_Suburban                            [1.9124064]\n",
      "school_setting_Urban                                 [1.33277]\n",
      "school_type_Non-public                              [2.235788]\n",
      "school_type_Public                                 [1.4629098]\n",
      "teaching_method_Experimental                       [5.3804803]\n",
      "teaching_method_Standard                          [-0.6383226]\n",
      "gender_Female                                      [2.3788478]\n",
      "gender_Male                                        [2.2255788]\n",
      "lunch_Does not qualify                             [2.1002777]\n",
      "lunch_Qualifies for reduced/free lunch             [1.5568472]\n",
      "系数b1:[2.3013573]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")#Sequential模型结构 多个网络层且无多余分支的堆叠 Dense就是常用的全连接层 运算就是output = activation(dot(input, kernel)+bias) units为该层的输出维度 而非输入维度  \n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)) #adam（前期降低损失迅速，随迭代次数衰减学习率）学习率提高一点 \n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) #整个数据一共遍历epoch遍 每一次拿batch_size个样本来算损失 所以一个epoch需要算epoch/batch_size遍 更新同样次数的参数\n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094a8c3",
   "metadata": {},
   "source": [
    "换个优化器 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079e56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 724us/step - loss: 4113.5874\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 975us/step - loss: 1722.8843\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 764us/step - loss: 388.4107\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 686us/step - loss: 52.7168\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 758us/step - loss: 35.8078\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 837us/step - loss: 25.8905\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 876us/step - loss: 19.8818\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 896us/step - loss: 16.6951\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 749us/step - loss: 15.3336\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 14.4935 - val_loss: 12.9766\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 13.7103\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 803us/step - loss: 13.1422\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 12.7336\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 12.6162\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 12.2739\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 12.2064\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 849us/step - loss: 12.1026\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 816us/step - loss: 12.0332\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 776us/step - loss: 11.9977\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.8157 - val_loss: 11.2576\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 802us/step - loss: 11.8613\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 908us/step - loss: 11.8706\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 799us/step - loss: 11.7904\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 11.8241\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 799us/step - loss: 11.7501\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.7636\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 894us/step - loss: 11.6917\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 962us/step - loss: 11.6721\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 920us/step - loss: 11.5589\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5616 - val_loss: 11.1334\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 802us/step - loss: 11.6622\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 853us/step - loss: 11.4764\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 798us/step - loss: 11.6349\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5620\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 799us/step - loss: 11.5445\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 834us/step - loss: 11.5486\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 732us/step - loss: 11.3633\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 688us/step - loss: 11.3835\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.3334\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.4165 - val_loss: 11.1604\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 834us/step - loss: 11.3498\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 728us/step - loss: 11.2817\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.3044\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.3205\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.2999\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.3171\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.1957\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 748us/step - loss: 11.2044\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 803us/step - loss: 11.3646\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2619 - val_loss: 12.3448\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 758us/step - loss: 11.2039\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.2354\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 690us/step - loss: 11.1900\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.4071\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 795us/step - loss: 11.1757\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 878us/step - loss: 11.2374\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 776us/step - loss: 11.2741\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 887us/step - loss: 11.1844\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 775us/step - loss: 11.1912\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0513 - val_loss: 10.8151\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 742us/step - loss: 11.2112\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2001\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 780us/step - loss: 11.1164\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 926us/step - loss: 11.1129\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1669\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 935us/step - loss: 11.1383\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 866us/step - loss: 11.1861\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 920us/step - loss: 11.0208\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 910us/step - loss: 11.1327\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0811 - val_loss: 10.8813\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 822us/step - loss: 11.1428\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.9397\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 935us/step - loss: 11.0030\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 11.0242\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 939us/step - loss: 10.9831\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.9688\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 908us/step - loss: 11.1046\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 864us/step - loss: 11.0314\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9500\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 10.9354 - val_loss: 10.5541\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 812us/step - loss: 11.0520\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 936us/step - loss: 10.9823\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.0355\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 888us/step - loss: 10.9897\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 930us/step - loss: 11.0555\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9304\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9602\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0052\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 10.9719\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9185 - val_loss: 10.4411\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 935us/step - loss: 10.9818\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 10.9099\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 798us/step - loss: 10.8604\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 10.9317\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 10.8746\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 799us/step - loss: 10.9526\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 860us/step - loss: 10.8861\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 10.8551\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 973us/step - loss: 10.9863\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8432 - val_loss: 10.6474\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.13061273]\n",
      "pretest                                           [0.94785774]\n",
      "school_setting_Rural                                 [2.50277]\n",
      "school_setting_Suburban                            [2.3733053]\n",
      "school_setting_Urban                               [1.8434454]\n",
      "school_type_Non-public                             [2.0387518]\n",
      "school_type_Public                                 [1.3717276]\n",
      "teaching_method_Experimental                        [5.718806]\n",
      "teaching_method_Standard                         [-0.29349995]\n",
      "gender_Female                                      [1.5669311]\n",
      "gender_Male                                        [1.3705822]\n",
      "lunch_Does not qualify                             [2.8142085]\n",
      "lunch_Qualifies for reduced/free lunch             [2.3104713]\n",
      "系数b1:[2.3174396]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.SGD(learning_rate=0.01,clipvalue=0.5))#梯度裁剪 Gradient Clipping +-0.5\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a2a91",
   "metadata": {},
   "source": [
    "自适应梯度 (对初始位置要求很严格 不然直接3000遍历还有1000损失 下降平缓均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bb9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1789.4215\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1289.4225\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 846us/step - loss: 1027.0938\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 845.3806\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 736us/step - loss: 709.0980\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 866us/step - loss: 602.5774\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 853us/step - loss: 516.8130\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 683us/step - loss: 446.4326\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 861us/step - loss: 387.8655\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 338.5983 - val_loss: 220.4021\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 874us/step - loss: 296.8811\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 261.3792\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 230.9930\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 797us/step - loss: 204.8732\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 182.3229\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 162.7804\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 763us/step - loss: 145.8385\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 727us/step - loss: 131.0442\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 833us/step - loss: 118.2161\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 107.0244 - val_loss: 66.7224\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 829us/step - loss: 97.2689\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 880us/step - loss: 88.7203\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 988us/step - loss: 81.2283\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 840us/step - loss: 74.6728\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 761us/step - loss: 68.8974\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 63.8631\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 723us/step - loss: 59.4292\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 999us/step - loss: 55.5355\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 52.1165\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 49.0954 - val_loss: 34.4505\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 867us/step - loss: 46.4540\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 776us/step - loss: 44.1053\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 42.0525\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 40.2595\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 927us/step - loss: 38.6481\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 961us/step - loss: 37.2249\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 936us/step - loss: 35.9663\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 34.8741\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 33.8901\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 33.0059 - val_loss: 28.5416\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 954us/step - loss: 32.2439\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 879us/step - loss: 31.5611\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 787us/step - loss: 30.9495\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 30.4114\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 29.9297\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 802us/step - loss: 29.5050\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 802us/step - loss: 29.1231\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 810us/step - loss: 28.7810\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 28.4778\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 28.2085 - val_loss: 28.1741\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 803us/step - loss: 27.9613\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 926us/step - loss: 27.7425\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 27.5462\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 920us/step - loss: 27.3654\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 906us/step - loss: 27.2068\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 27.0546\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 876us/step - loss: 26.9204\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 958us/step - loss: 26.7973\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 26.6820\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 26.5766 - val_loss: 28.5344\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 967us/step - loss: 26.4794\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 863us/step - loss: 26.3932\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 973us/step - loss: 26.3097\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 26.2311\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 960us/step - loss: 26.1586\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 26.0911\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 26.0265\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 862us/step - loss: 25.9645\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 965us/step - loss: 25.9040\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 25.8469 - val_loss: 28.6672\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 999us/step - loss: 25.7921\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 951us/step - loss: 25.7399\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 895us/step - loss: 25.6895\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 25.6409\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 742us/step - loss: 25.5937\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 25.5464\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 806us/step - loss: 25.5022\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 25.4576\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 25.4144\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 25.3716 - val_loss: 28.5361\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 25.3299\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 774us/step - loss: 25.2899\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 758us/step - loss: 25.2493\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 25.2086\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 934us/step - loss: 25.1689\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 25.1306\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 25.0908\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 25.0524\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 25.0142\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 24.9767 - val_loss: 28.2305\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 901us/step - loss: 24.9396\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 24.9030\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 922us/step - loss: 24.8656\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 24.8288\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 24.7929\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 24.7571\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 24.7214\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 798us/step - loss: 24.6859\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 24.6501\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 24.6157 - val_loss: 27.8464\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.53796375]\n",
      "pretest                                           [0.93451107]\n",
      "school_setting_Rural                               [1.2120169]\n",
      "school_setting_Suburban                            [1.2413573]\n",
      "school_setting_Urban                               [0.9860988]\n",
      "school_type_Non-public                            [0.07061936]\n",
      "school_type_Public                                  [0.466232]\n",
      "teaching_method_Experimental                       [1.3462254]\n",
      "teaching_method_Standard                          [0.60679626]\n",
      "gender_Female                                     [0.27702513]\n",
      "gender_Male                                      [-0.07801922]\n",
      "lunch_Does not qualify                             [1.0660604]\n",
      "lunch_Qualifies for reduced/free lunch             [0.4285758]\n",
      "系数b1:[0.56309]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adagrad(learning_rate=0.01,epsilon=1e-6))\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868c0b",
   "metadata": {},
   "source": [
    "结合梯度平方的指数移动平均数来调节学习率的变化。能够在不稳定（Non-Stationary）的目标函数情况下进行很好地收敛。递归神经网络时的一个良好选择？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6285a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 5193.2158\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 965us/step - loss: 1063.4326\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 107.0319\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 45.8966\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.6281\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 16.3434\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 14.3593\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 13.2831\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.5435\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 12.2024 - val_loss: 11.7068\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.9223\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.9092\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.8268\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.6692\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.6327\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5758\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5026\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.6247\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.4966\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 11.5027 - val_loss: 12.1427\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5529\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3236\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 11.4084\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3505\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1948\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3899\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 938us/step - loss: 11.2060\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2626\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2832\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2090 - val_loss: 13.1003\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1755\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1076\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 856us/step - loss: 11.1404\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1067\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1304\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1648\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0591\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0895\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1012\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 11.1622 - val_loss: 10.8800\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8938\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1038\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0013\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9805\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9927\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9683\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0605\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9542\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9664\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 10.8863 - val_loss: 10.4252\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8495\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9232\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8634\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8267\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0630\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8639\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8051\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7757\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9162\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 10.9793 - val_loss: 10.7084\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8636\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7324\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8077\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8121\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8519\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8120\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7604\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7252\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8603\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 10.8156 - val_loss: 10.1338\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8533\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8405\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.6553\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7166\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8046\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8252\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.6826\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7430\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8492\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 10.7551 - val_loss: 10.0365\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8166\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7309\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8432\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9111\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7651\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.6457\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7717\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 922us/step - loss: 10.7685\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7749\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 10.7722 - val_loss: 13.7889\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7575\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7730\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8366\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7432\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8363\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7538\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7730\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.6559\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7957\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 10.5645 - val_loss: 9.9494\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                        [-0.01682898]\n",
      "pretest                                           [0.91859967]\n",
      "school_setting_Rural                               [2.7543132]\n",
      "school_setting_Suburban                             [3.224873]\n",
      "school_setting_Urban                               [2.6944036]\n",
      "school_type_Non-public                              [2.754734]\n",
      "school_type_Public                                 [2.5426297]\n",
      "teaching_method_Experimental                       [5.7861357]\n",
      "teaching_method_Standard                          [-0.2958393]\n",
      "gender_Female                                      [3.0352387]\n",
      "gender_Male                                        [2.9728475]\n",
      "lunch_Does not qualify                             [3.6057596]\n",
      "lunch_Qualifies for reduced/free lunch             [2.8130808]\n",
      "系数b1:[3.0753393]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.RMSprop(learning_rate=0.01, rho=0.9, epsilon=1e-6)) #rho衰减系数 epsilon数值稳定性的小常数？\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
