{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0495bae0-fbd3-4dcc-bb6d-d31c36da394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292022a1-4a45-47e7-ad5c-93f938d45ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv(\"data_set/从11个特征预测学生的测试分数.csv\")\n",
    "X , Y = orig_data.iloc[:,0:10] , orig_data.iloc[:,-1] #切片\n",
    "X = X.drop(columns=[\"school\",\"classroom\",\"student_id\"],axis=1)#按列丢弃无关项\n",
    "X = pd.get_dummies(X,columns=[\"school_setting\",\"school_type\",\"teaching_method\",\"gender\",\"lunch\"],dtype=int)#独热编码 #orig_data.iloc[0:5,] X.iloc[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71a365",
   "metadata": {},
   "source": [
    "一层神经网络模型  \n",
    "激活函数f(x)= x  \n",
    "损失函数均方误差  \n",
    "优化器Adam(默认比较优秀的优化器 结合了自适应梯度Adagrad和RMSProp防梯度急剧下降的优点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b907d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 138.3500\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 37.8864\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 30.3920\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 24.7600\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 20.8762\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 18.3806\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 16.7339\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 15.6809\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 14.9663\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 14.3622 - val_loss: 12.9270\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 13.9681\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 13.5522\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 13.3197\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 13.1561\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 715us/step - loss: 13.0034\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.8273\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.7497\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.7222\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.5958\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 903us/step - loss: 12.4683 - val_loss: 12.1338\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 538us/step - loss: 12.4644\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.3855\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.3645\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.3382\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 12.2595\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.2287\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 12.1451\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 12.1016\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 658us/step - loss: 12.1317\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.0360 - val_loss: 11.3365\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.9741\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 733us/step - loss: 11.9553\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 612us/step - loss: 11.8647\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.8963\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.9356\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.8005\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.7997\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.7449\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 733us/step - loss: 11.7520\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 11.6169 - val_loss: 11.7357\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 11.6776\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.5625\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.7029\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.6235\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.4943\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4181\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.5352\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3715\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3450\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 978us/step - loss: 11.4538 - val_loss: 11.9113\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4680\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.2643\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.2247\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3473\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3537\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4089\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4157\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.3345\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 11.2223\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 932us/step - loss: 11.1527 - val_loss: 10.6350\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.0526\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1905\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9450\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1425\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.0007\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9706\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9124\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3056\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 11.0141\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 921us/step - loss: 10.8798 - val_loss: 10.4309\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.9069\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8482\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8600\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8479\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8627\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8293\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.7724\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7724\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7298\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 10.7052 - val_loss: 10.5444\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.7694\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.9822\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.8379\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.7145\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 10.7332\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 10.8456\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8128\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.7478\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.6535\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 945us/step - loss: 10.7473 - val_loss: 10.5583\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7206\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8851\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.6395\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.6854\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8480\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9921\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7031\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8467\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.6493\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 947us/step - loss: 10.6290 - val_loss: 10.2549\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                          [0.0398774]\n",
      "pretest                                           [0.93515086]\n",
      "school_setting_Rural                               [2.0282297]\n",
      "school_setting_Suburban                             [2.250986]\n",
      "school_setting_Urban                               [1.6923932]\n",
      "school_type_Non-public                             [3.1675136]\n",
      "school_type_Public                                 [2.7471998]\n",
      "teaching_method_Experimental                       [5.8295507]\n",
      "teaching_method_Standard                         [-0.24829806]\n",
      "gender_Female                                      [2.2572856]\n",
      "gender_Male                                         [2.141871]\n",
      "lunch_Does not qualify                             [3.0243578]\n",
      "lunch_Qualifies for reduced/free lunch             [2.3615925]\n",
      "系数b1:[3.144413]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")#Sequential模型结构 多个网络层且无多余分支的堆叠 Dense就是常用的全连接层 运算就是output = activation(dot(input, kernel)+bias) units为该层的输出维度 而非输入维度  \n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)) #adam（前期降低损失迅速，随迭代次数衰减学习率） 所以可以一开始把学习率提高一点 \n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) #整个数据一共遍历epoch遍 每一次拿batch_size个样本来算损失 所以一个epoch需要算epoch/batch_size遍 更新同样次数的参数\n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094a8c3",
   "metadata": {},
   "source": [
    "换个优化器 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079e56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 6714.5879\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 677us/step - loss: 3484.5496\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 1332.0724\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 250.2405\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 50.1709\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 34.1167\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 25.4268\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 19.6385\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 16.7157\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 15.1308 - val_loss: 13.9926\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 14.1585\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 13.5426\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.9802\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.6660\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 12.2901\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.1918\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.9338\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.8360\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.7899\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 11.6850 - val_loss: 10.9424\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.6479\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.6015\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.5007\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.5057\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.5554\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4624\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.5011\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.3722\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.3436\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 11.3671 - val_loss: 11.9030\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.4599\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.2892\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3355\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.3087\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3249\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.2462\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.2980\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.2118\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.2100\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 11.2157 - val_loss: 10.7289\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.3027\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1473\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.3264\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1780\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1996\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.1735\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.2007\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.2452\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.1191\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 978us/step - loss: 11.0947 - val_loss: 10.6309\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1026\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.1106\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1379\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 11.0386\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.1212\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1985\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.0602\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0364\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1454\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0958 - val_loss: 11.3854\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.0249\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.0596\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.0687\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9313\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.0399\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9632\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9174\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9692\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9919\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 10.9959 - val_loss: 10.3843\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9650\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9060\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.0113\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9789\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9003\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.9050\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.8511\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.9021\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.7838\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 10.7869 - val_loss: 11.6779\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8892\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9544\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8815\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.9539\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 10.8290\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.9084\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 10.8678\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8675\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.9314\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 10.8399 - val_loss: 11.0456\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.8145\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.8022\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.7995\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.8512\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.8607\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 10.8202\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7335\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.8012\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.7406\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 10.8593 - val_loss: 10.1879\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.07874302]\n",
      "pretest                                           [0.95000905]\n",
      "school_setting_Rural                               [1.8959496]\n",
      "school_setting_Suburban                            [1.8884774]\n",
      "school_setting_Urban                               [1.3053432]\n",
      "school_type_Non-public                             [2.8845906]\n",
      "school_type_Public                                 [2.2793083]\n",
      "teaching_method_Experimental                        [5.638399]\n",
      "teaching_method_Standard                         [-0.40714425]\n",
      "gender_Female                                      [2.4054227]\n",
      "gender_Male                                        [2.2231622]\n",
      "lunch_Does not qualify                             [2.6128657]\n",
      "lunch_Qualifies for reduced/free lunch             [2.0044973]\n",
      "系数b1:[2.3161855]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.SGD(learning_rate=0.01,clipvalue=0.5))#梯度裁剪 Gradient Clipping +-0.5\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a2a91",
   "metadata": {},
   "source": [
    "自适应梯度 (对初始位置要求很严格 不然直接3000遍历还有1000损失 下降平缓均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adagrad.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 555us/step - loss: 3178.6213\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 3101.6084\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 3052.4133\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 3013.0293\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2979.2341\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 2949.3506\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2922.2849\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2897.3540\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2874.1895\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2852.5229 - val_loss: 1965.2296\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2832.0784\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2812.7092\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2794.2231\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2776.5056\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2759.5320\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2743.2446\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2727.5295\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2712.3157\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2697.6128\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 928us/step - loss: 2683.3154 - val_loss: 1839.7069\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2669.4380\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2655.9717\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2642.8394\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2630.0437\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 2617.5481\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2605.3491\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2593.4338\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2581.7957\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2570.3831\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 934us/step - loss: 2559.2358 - val_loss: 1747.2244\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2548.2964\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2537.5381\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2526.9983\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2516.6570\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2506.4858\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2496.4631\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 639us/step - loss: 2486.6416\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2476.9922\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2467.4924\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 2458.1384 - val_loss: 1671.8235\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2448.9368\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2439.8528\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2430.9114\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2422.0781\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2413.3552\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2404.7686\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 2396.3035\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2387.9297\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2379.6738\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2371.5308 - val_loss: 1607.2589\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2363.4902\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2355.5486\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2347.7124\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 2339.9585\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2332.2737\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2324.6985\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2317.1997\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2309.7981\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2302.4663\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 2295.2341 - val_loss: 1550.4572\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2288.0564\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2280.9607\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2273.9282\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2266.9712\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 733us/step - loss: 2260.0608\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 2253.2405\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2246.4897\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2239.8132\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2233.1826\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 997us/step - loss: 2226.6196 - val_loss: 1499.4553\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2220.1194\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2213.6716\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2207.2781\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 2200.9543\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 2194.6765\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2188.4580\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2182.2930\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2176.1882\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2170.1394\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 2164.1033 - val_loss: 1453.0566\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2158.1482\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2152.2483\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2146.3850\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2140.5657\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2134.7832\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2129.0535\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2123.3699\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 2117.7322\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2112.1255\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2106.5610 - val_loss: 1410.4098\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 2101.0437\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2095.5662\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2090.1575\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2084.7634\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2079.4143\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 696us/step - loss: 2074.1072\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 595us/step - loss: 2068.8345\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 2063.6123\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 2058.4199\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 2053.2480 - val_loss: 1370.9662\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                          [0.6256504]\n",
      "pretest                                             [0.184872]\n",
      "school_setting_Rural                             [-0.24554646]\n",
      "school_setting_Suburban                          [-0.46157125]\n",
      "school_setting_Urban                             [-0.20222749]\n",
      "school_type_Non-public                            [0.55773824]\n",
      "school_type_Public                                [0.31244355]\n",
      "teaching_method_Experimental                      [0.07381356]\n",
      "teaching_method_Standard                          [0.00425416]\n",
      "gender_Female                                     [0.28454506]\n",
      "gender_Male                                       [0.23316084]\n",
      "lunch_Does not qualify                            [0.59414774]\n",
      "lunch_Qualifies for reduced/free lunch            [0.14591716]\n",
      "系数b1:[0.13952617]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adagrad(learning_rate=0.01,epsilon=1e-6))\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868c0b",
   "metadata": {},
   "source": [
    "结合梯度平方的指数移动平均数来调节学习率的变化。能够在不稳定（Non-Stationary）的目标函数情况下进行很好地收敛。递归神经网络时的一个良好选择？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 1302.6537\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 993.4156\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 732.9528\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 513.5810\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 336.7482\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 200.0782\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 103.4829\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 46.3887\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 24.1346\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 21.3693 - val_loss: 22.2587\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 21.0094\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 20.6742\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 20.2996\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 20.0198\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 19.6826\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 19.3888\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 19.0902\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 18.8392\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 752us/step - loss: 18.5546\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 18.3077 - val_loss: 18.8714\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 18.0085\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 17.7738\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 17.5572\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 658us/step - loss: 17.3181\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 642us/step - loss: 17.0974\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 16.8839\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 16.6488\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 16.4284\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 16.2596\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 948us/step - loss: 16.0606 - val_loss: 16.4088\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 15.8516\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 15.7214\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 15.5341\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 15.3629\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 15.2250\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 15.0640\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 14.9112\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 14.7861\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 14.6312\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 14.5128 - val_loss: 14.5613\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 14.3861\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 14.2523\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 14.1340\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 639us/step - loss: 14.0175\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 639us/step - loss: 13.9106\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 613us/step - loss: 13.8453\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 696us/step - loss: 13.7180\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 649us/step - loss: 13.6288\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.5142\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 999us/step - loss: 13.4480 - val_loss: 13.2946\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 13.3511\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.2871\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.1935\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.1378\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 13.0880\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.0096\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.9438\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.8814\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.8377\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 921us/step - loss: 12.7758 - val_loss: 12.4632\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.7211\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.6706\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 12.6164\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 12.6027\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.5452\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.5063\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.4704\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.4270\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.4104\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.3649 - val_loss: 12.2930\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.3369\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 12.3101\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.2952\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.2518\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.2289\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.1945\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 12.1832\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 12.1635\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 677us/step - loss: 12.1517\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.1103 - val_loss: 11.8019\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.0991\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.0658\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.0803\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 544us/step - loss: 12.0413\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.0291\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.0181\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.0254\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.9792\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.9897\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.9930 - val_loss: 11.7302\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.9604\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.9542\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.9565\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.9254\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.9396\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.8999\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.9133\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.8982\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.8889\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.8718 - val_loss: 11.6521\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.29185757]\n",
      "pretest                                            [1.0178573]\n",
      "school_setting_Rural                               [1.3715783]\n",
      "school_setting_Suburban                            [0.3344527]\n",
      "school_setting_Urban                             [-0.00229162]\n",
      "school_type_Non-public                             [1.5811973]\n",
      "school_type_Public                                [0.49708682]\n",
      "teaching_method_Experimental                       [4.0192275]\n",
      "teaching_method_Standard                          [-1.5990504]\n",
      "gender_Female                                      [0.8730952]\n",
      "gender_Male                                        [0.7085496]\n",
      "lunch_Does not qualify                            [0.72586983]\n",
      "lunch_Qualifies for reduced/free lunch            [0.91268396]\n",
      "系数b1:[1.2978803]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.RMSprop(learning_rate=0.01, rho=0.9, epsilon=1e-6)) #rho衰减系数 epsilon数值稳定性的小常数？\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d14d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
