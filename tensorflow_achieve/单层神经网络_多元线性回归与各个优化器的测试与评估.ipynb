{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0495bae0-fbd3-4dcc-bb6d-d31c36da394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292022a1-4a45-47e7-ad5c-93f938d45ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_student</th>\n",
       "      <th>pretest</th>\n",
       "      <th>school_setting_Rural</th>\n",
       "      <th>school_setting_Suburban</th>\n",
       "      <th>school_setting_Urban</th>\n",
       "      <th>school_type_Non-public</th>\n",
       "      <th>school_type_Public</th>\n",
       "      <th>teaching_method_Experimental</th>\n",
       "      <th>teaching_method_Standard</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>lunch_Does not qualify</th>\n",
       "      <th>lunch_Qualifies for reduced/free lunch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>30.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_student  pretest  school_setting_Rural  school_setting_Suburban  \\\n",
       "0          20.0     62.0                     0                        0   \n",
       "1          20.0     66.0                     0                        0   \n",
       "2          20.0     64.0                     0                        0   \n",
       "3          20.0     61.0                     0                        0   \n",
       "4          20.0     64.0                     0                        0   \n",
       "...         ...      ...                   ...                      ...   \n",
       "2128       30.0     39.0                     0                        0   \n",
       "2129       30.0     38.0                     0                        0   \n",
       "2130       30.0     45.0                     0                        0   \n",
       "2131       30.0     46.0                     0                        0   \n",
       "2132       30.0     41.0                     0                        0   \n",
       "\n",
       "      school_setting_Urban  school_type_Non-public  school_type_Public  \\\n",
       "0                        1                       1                   0   \n",
       "1                        1                       1                   0   \n",
       "2                        1                       1                   0   \n",
       "3                        1                       1                   0   \n",
       "4                        1                       1                   0   \n",
       "...                    ...                     ...                 ...   \n",
       "2128                     1                       0                   1   \n",
       "2129                     1                       0                   1   \n",
       "2130                     1                       0                   1   \n",
       "2131                     1                       0                   1   \n",
       "2132                     1                       0                   1   \n",
       "\n",
       "      teaching_method_Experimental  teaching_method_Standard  gender_Female  \\\n",
       "0                                0                         1              1   \n",
       "1                                0                         1              1   \n",
       "2                                0                         1              0   \n",
       "3                                0                         1              1   \n",
       "4                                0                         1              0   \n",
       "...                            ...                       ...            ...   \n",
       "2128                             0                         1              1   \n",
       "2129                             0                         1              1   \n",
       "2130                             0                         1              1   \n",
       "2131                             0                         1              0   \n",
       "2132                             0                         1              0   \n",
       "\n",
       "      gender_Male  lunch_Does not qualify  \\\n",
       "0               0                       1   \n",
       "1               0                       1   \n",
       "2               1                       1   \n",
       "3               0                       1   \n",
       "4               1                       1   \n",
       "...           ...                     ...   \n",
       "2128            0                       1   \n",
       "2129            0                       0   \n",
       "2130            0                       0   \n",
       "2131            1                       0   \n",
       "2132            1                       0   \n",
       "\n",
       "      lunch_Qualifies for reduced/free lunch  \n",
       "0                                          0  \n",
       "1                                          0  \n",
       "2                                          0  \n",
       "3                                          0  \n",
       "4                                          0  \n",
       "...                                      ...  \n",
       "2128                                       0  \n",
       "2129                                       1  \n",
       "2130                                       1  \n",
       "2131                                       1  \n",
       "2132                                       1  \n",
       "\n",
       "[2133 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data = pd.read_csv(\"data_set/从11个特征预测学生的测试分数.csv\")\n",
    "X , Y = orig_data.iloc[:,0:10] , orig_data.iloc[:,-1] #切片\n",
    "X = X.drop(columns=[\"school\",\"classroom\",\"student_id\"],axis=1)#按列丢弃无关项\n",
    "X = pd.get_dummies(X,columns=[\"school_setting\",\"school_type\",\"teaching_method\",\"gender\",\"lunch\"],dtype=int)#独热编码 #orig_data.iloc[0:5,] X.iloc[0:5,]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71a365",
   "metadata": {},
   "source": [
    "一层神经网络模型  \n",
    "激活函数f(x)= x  \n",
    "损失函数均方误差  \n",
    "优化器Adam(默认比较优秀的优化器 结合了自适应梯度Adagrad和RMSProp防梯度急剧下降的优点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b907d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 623us/step - loss: 1295.6588\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 80.8356\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 24.4455\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 23.6052\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 22.8562\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 22.0683\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 21.2628\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 20.5386\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 19.8143\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 19.1004 - val_loss: 22.5803\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 639us/step - loss: 18.4475\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 663us/step - loss: 17.7956\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 17.1975\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 16.6457\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 16.1591\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 15.7058\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 15.2662\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 14.8944\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 14.5752\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 14.1933 - val_loss: 14.3020\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 658us/step - loss: 13.8828\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 658us/step - loss: 13.6599\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 13.4019\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 677us/step - loss: 13.2271\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 715us/step - loss: 13.0627\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 696us/step - loss: 12.8912\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 12.7182\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 809us/step - loss: 12.5985\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.4963\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 958us/step - loss: 12.3720 - val_loss: 12.1025\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.3042\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.1789\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.1892\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.0901\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.0748\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.9771\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.9556\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.9286\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.9084\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 997us/step - loss: 11.7953 - val_loss: 11.5834\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.7924\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.8183\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.7338\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.6989\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.7315\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.7031\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.6218\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.6526\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.6230\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 997us/step - loss: 11.5858 - val_loss: 11.4543\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 11.5588\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.5636\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 639us/step - loss: 11.5569\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 786us/step - loss: 11.4867\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.4967\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 11.4634\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 11.3830\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 11.3949\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 639us/step - loss: 11.3780\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3991 - val_loss: 11.2864\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3204\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3465\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.3209\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3582\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.2864\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.2264\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.2524\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.2694\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.2124\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 993us/step - loss: 11.3235 - val_loss: 11.7496\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3334\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1605\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0987\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.1313\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.2341\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4283\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1407\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.0511\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1091\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9835 - val_loss: 10.7248\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0871\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.1840\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0534\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.9377\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.9148\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.1777\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.9680\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.9550\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.8668\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9035 - val_loss: 11.3942\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 563us/step - loss: 10.9764\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8017\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.9817\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.9927\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 10.8229\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 10.8323\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8414\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8983\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.8246\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7360 - val_loss: 11.3928\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.11872468]\n",
      "pretest                                            [0.9571189]\n",
      "school_setting_Rural                               [2.4730809]\n",
      "school_setting_Suburban                            [2.3729815]\n",
      "school_setting_Urban                               [1.7820463]\n",
      "school_type_Non-public                             [2.6381824]\n",
      "school_type_Public                                 [1.9594702]\n",
      "teaching_method_Experimental                       [5.6467996]\n",
      "teaching_method_Standard                         [-0.35725275]\n",
      "gender_Female                                       [2.228273]\n",
      "gender_Male                                        [2.0363457]\n",
      "lunch_Does not qualify                             [2.0765634]\n",
      "lunch_Qualifies for reduced/free lunch             [1.4632305]\n",
      "系数b1:[2.4433339]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")#Sequential模型结构 多个网络层且无多余分支的堆叠 Dense就是常用的全连接层 运算就是output = activation(dot(input, kernel)+bias) units为该层的输出维度 而非输入维度  \n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)) #adam（前期降低损失迅速，随迭代次数衰减学习率）学习率提高一点 \n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) #整个数据一共遍历epoch遍 每一次拿batch_size个样本来算损失 所以一个epoch需要算epoch/batch_size遍 更新同样次数的参数\n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094a8c3",
   "metadata": {},
   "source": [
    "换个优化器 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079e56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 1077.6292\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 152.2503\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 30.5355\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 23.3734\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 19.6744\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 18.1315\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 16.9032\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 15.8776\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 15.0975\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 14.5020 - val_loss: 13.5803\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.9997\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.6953\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 13.2510\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 13.1165\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 12.9533\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.8420\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 12.7090\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.6905\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.4957\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 12.4286 - val_loss: 12.5160\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.3695\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.3696\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.2349\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.2653\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 12.2076\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 12.2517\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 715us/step - loss: 12.2180\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 12.2777\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.2015\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 12.1726 - val_loss: 11.2893\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.1523\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.9341\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.0195\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.0056\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 12.0473\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.9786\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.8386\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.9200\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.8690\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 11.8476 - val_loss: 12.0909\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.8002\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.8464\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.8719\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.8161\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.7714\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.8399\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 11.7326\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.6705\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.6874\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.7394 - val_loss: 11.9135\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.6879\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.6842\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.6371\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.5949\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 11.5513\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.5326\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.5918\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.5468\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4870\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 922us/step - loss: 11.5205 - val_loss: 12.2672\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.4294\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 11.4740\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3862\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3338\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4675\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.4460\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.4232\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3874\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.3919\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 997us/step - loss: 11.4734 - val_loss: 10.8893\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.3853\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.3663\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3879\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.4345\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.3490\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.3760\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.3224\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1757\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1863\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 11.2977 - val_loss: 10.7511\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.3305\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.2589\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 11.1593\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.2343\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.1423\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 11.2336\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1476\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1102\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1772\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 959us/step - loss: 11.1667 - val_loss: 12.7053\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0670\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0987\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0573\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0571\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.0351\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.0284\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 11.1783\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.0456\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.9774\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 989us/step - loss: 11.0181 - val_loss: 10.5145\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.16114482]\n",
      "pretest                                            [0.9575079]\n",
      "school_setting_Rural                               [1.9258667]\n",
      "school_setting_Suburban                            [1.6065767]\n",
      "school_setting_Urban                               [0.9075529]\n",
      "school_type_Non-public                             [2.5805194]\n",
      "school_type_Public                                 [1.6018025]\n",
      "teaching_method_Experimental                       [5.2826767]\n",
      "teaching_method_Standard                          [-0.7350256]\n",
      "gender_Female                                      [1.9389988]\n",
      "gender_Male                                        [1.7429425]\n",
      "lunch_Does not qualify                             [2.0719492]\n",
      "lunch_Qualifies for reduced/free lunch             [1.3944806]\n",
      "系数b1:[2.4931471]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.SGD(learning_rate=0.01,clipvalue=0.5))#梯度裁剪 Gradient Clipping +-0.5\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a2a91",
   "metadata": {},
   "source": [
    "自适应梯度 (对初始位置要求很严格 不然直接3000遍历还有1000损失 下降平缓均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bb9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 545us/step - loss: 8563.9258\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 7370.7891\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 6664.7520\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 6129.4712\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 5692.1816\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 5321.7017\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 4998.3179\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 4712.6245\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 4456.2007\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4224.2217 - val_loss: 2799.4761\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 4012.4739\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 3817.7339\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 3637.9688\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 3471.2722\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 3316.0527\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 3170.9893\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 3035.4768\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2908.4202\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 2788.6846\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 908us/step - loss: 2675.8801 - val_loss: 1693.4231\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2569.4475\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2468.7051\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 2373.1509\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2282.5779\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2196.7268\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2114.9436\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 2037.1592\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 1962.6586\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 1891.8956\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 1824.4077 - val_loss: 1100.5785\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 1759.8007\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 1698.1549\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 1639.3212\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 1582.8019\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 1528.9246\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 1477.2783\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 1427.6505\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 1380.1862\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 1334.5602\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 1290.9645 - val_loss: 742.8773\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 1248.9758\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 1208.8969\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 1170.1985\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 1133.0184\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 1097.0120\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 1062.6200\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 1029.3975\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 997.4243\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 966.7614\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 921us/step - loss: 937.1245 - val_loss: 516.1447\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 908.6108\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 881.1653\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 854.7335\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 829.2913\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 804.7994\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 781.0522\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 758.1788\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 736.0745\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 714.8179\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 929us/step - loss: 694.3532 - val_loss: 369.0926\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 674.5767\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 655.4296\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 637.0442\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 619.2825\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 602.0299\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 585.3742\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 569.3625\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 553.9164\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 538.9721\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 905us/step - loss: 524.5714 - val_loss: 273.0484\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 510.5945\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 497.1398\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 484.0898\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 471.4791\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 459.3016\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 447.4954\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 436.1577\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 425.1521\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 414.5381\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 886us/step - loss: 404.2784 - val_loss: 210.5691\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 394.3179\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 384.6781\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 375.3315\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 526us/step - loss: 366.2613\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 639us/step - loss: 357.5505\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 349.1296\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 341.0150\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 333.0754\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 325.4568\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 318.0375 - val_loss: 170.3226\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 310.8633\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 303.9447\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 297.2445\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 290.7563\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 284.4478\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 278.3702\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 272.4266\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 266.7202\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 261.2060\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 899us/step - loss: 255.8395 - val_loss: 145.0628\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                          [1.1354042]\n",
      "pretest                                            [0.4575505]\n",
      "school_setting_Rural                               [1.1103157]\n",
      "school_setting_Suburban                             [0.889758]\n",
      "school_setting_Urban                               [0.3907171]\n",
      "school_type_Non-public                             [1.0104437]\n",
      "school_type_Public                                 [0.7847789]\n",
      "teaching_method_Experimental                       [1.1097921]\n",
      "teaching_method_Standard                           [1.1146752]\n",
      "gender_Female                                      [1.6188519]\n",
      "gender_Male                                       [0.88173795]\n",
      "lunch_Does not qualify                             [0.9200035]\n",
      "lunch_Qualifies for reduced/free lunch             [0.7879967]\n",
      "系数b1:[1.0013348]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adagrad(learning_rate=0.01,epsilon=1e-6))\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868c0b",
   "metadata": {},
   "source": [
    "结合梯度平方的指数移动平均数来调节学习率的变化。能够在不稳定（Non-Stationary）的目标函数情况下进行很好地收敛。递归神经网络时的一个良好选择？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6285a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 461.0370\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 21.8252\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 17.9568\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 15.7696\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 677us/step - loss: 14.4441\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 13.5182\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 13.0097\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 12.6392\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 12.3692\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 12.2267 - val_loss: 13.3907\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.1429\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 12.1688\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 12.0924\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.9951\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.9486\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.7802\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.8831\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.6574\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.7383\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 11.6589 - val_loss: 11.0170\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.5692\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.6480\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.4350\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.4922\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.4364\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.3527\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.4604\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.2325\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.3622\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 11.2915 - val_loss: 11.3335\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.4923\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.2900\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 602us/step - loss: 11.2538\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.3393\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.2717\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.2899\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.1345\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.1764\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.2743\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 11.0850 - val_loss: 10.6270\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 11.1610\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.1445\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.1625\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.0608\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.1967\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.0246\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.0521\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9664\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.0137\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 11.0499 - val_loss: 10.4511\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.0816\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.0034\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9068\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9130\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.0153\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9232\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 10.9040\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8516\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 10.9766\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 903us/step - loss: 10.9630 - val_loss: 10.5395\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8514\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9201\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 10.8864\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9433\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 10.8314\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 451us/step - loss: 10.9123\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 10.8532\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8741\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8370\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 10.8669 - val_loss: 12.2188\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.9504\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.7297\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8418\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8355\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8774\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8287\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8863\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.6669\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 10.9409\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 903us/step - loss: 11.0206 - val_loss: 10.0936\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8374\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 583us/step - loss: 10.8169\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.8705\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 10.7877\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.7761\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.8139\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7988\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7757\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 10.8027\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.6242 - val_loss: 10.1448\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.6626\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 10.7336\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8286\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.8971\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 10.7921\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.7481\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.7435\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 477us/step - loss: 10.8182\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 10.8304\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 940us/step - loss: 10.8160 - val_loss: 10.0458\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                        [-0.01318139]\n",
      "pretest                                           [0.91796386]\n",
      "school_setting_Rural                               [2.3871546]\n",
      "school_setting_Suburban                            [2.8077688]\n",
      "school_setting_Urban                                [2.280796]\n",
      "school_type_Non-public                             [2.5738456]\n",
      "school_type_Public                                 [2.2405736]\n",
      "teaching_method_Experimental                        [6.400372]\n",
      "teaching_method_Standard                          [0.31356776]\n",
      "gender_Female                                      [3.0332727]\n",
      "gender_Male                                        [2.8418367]\n",
      "lunch_Does not qualify                             [2.9183874]\n",
      "lunch_Qualifies for reduced/free lunch             [2.1972995]\n",
      "系数b1:[3.4619405]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.RMSprop(learning_rate=0.01, rho=0.9, epsilon=1e-6)) #rho衰减系数 epsilon数值稳定性的小常数？\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d14d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
