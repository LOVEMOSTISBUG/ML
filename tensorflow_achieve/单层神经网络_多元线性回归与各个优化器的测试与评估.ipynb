{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0495bae0-fbd3-4dcc-bb6d-d31c36da394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292022a1-4a45-47e7-ad5c-93f938d45ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv(\"data_set/从11个特征预测学生的测试分数.csv\")\n",
    "X , Y = orig_data.iloc[:,0:10] , orig_data.iloc[:,-1] #切片\n",
    "X = X.drop(columns=[\"school\",\"classroom\",\"student_id\"],axis=1)#按列丢弃无关项\n",
    "X = pd.get_dummies(X,columns=[\"school_setting\",\"school_type\",\"teaching_method\",\"gender\",\"lunch\"],dtype=int)#独热编码 #orig_data.iloc[0:5,] X.iloc[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71a365",
   "metadata": {},
   "source": [
    "一层神经网络模型  \n",
    "激活函数f(x)= x  \n",
    "损失函数均方误差  \n",
    "优化器Adam(默认比较优秀的优化器 结合了自适应梯度Adagrad和RMSProp防梯度急剧下降的优点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b907d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 868us/step - loss: 633.6257\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 26.6278\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 448us/step - loss: 21.5082\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 469us/step - loss: 20.7557\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 483us/step - loss: 19.9873\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 567us/step - loss: 19.2612\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 450us/step - loss: 18.4861\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 17.8040\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 517us/step - loss: 17.1688\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 16.5420 - val_loss: 16.6993\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 16.0043\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 15.4770\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 687us/step - loss: 15.0206\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 14.6165\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 14.2564\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 13.9417\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 13.6803\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 13.4143\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 466us/step - loss: 13.1988\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 13.0627 - val_loss: 12.5937\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 460us/step - loss: 12.8594\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 464us/step - loss: 12.7371\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 12.5868\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 553us/step - loss: 12.5000\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 12.4316\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 12.3697\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 12.3260\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 12.2395\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 12.1784\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 12.1711 - val_loss: 12.1093\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 586us/step - loss: 12.1370\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 648us/step - loss: 12.0493\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 539us/step - loss: 12.0321\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 658us/step - loss: 12.0442\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 12.0126\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.9421\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.9175\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.8605\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 608us/step - loss: 11.8681\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 850us/step - loss: 11.8405 - val_loss: 11.9197\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 660us/step - loss: 11.8475\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 11.7923\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 11.8954\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 462us/step - loss: 11.7826\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 504us/step - loss: 11.7683\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 11.6845\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 510us/step - loss: 11.7173\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 11.7073\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 11.6584\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 846us/step - loss: 11.5801 - val_loss: 11.7062\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 659us/step - loss: 11.5869\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 510us/step - loss: 11.5497\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 11.5470\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 498us/step - loss: 11.5739\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 476us/step - loss: 11.5081\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 495us/step - loss: 11.4625\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.5183\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 11.5979\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 11.4641\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 942us/step - loss: 11.3939 - val_loss: 10.8496\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 578us/step - loss: 11.3645\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 11.4119\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 553us/step - loss: 11.3621\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 520us/step - loss: 11.2653\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 691us/step - loss: 11.2983\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 11.2412\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 488us/step - loss: 11.2659\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 11.1787\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.3140\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 723us/step - loss: 11.2148 - val_loss: 10.7509\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 779us/step - loss: 11.3600\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 11.1056\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 11.0941\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 507us/step - loss: 11.0641\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 491us/step - loss: 10.9488\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 11.1584\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 493us/step - loss: 11.0096\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 495us/step - loss: 11.0550\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 11.0020\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 925us/step - loss: 11.1644 - val_loss: 10.8579\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 561us/step - loss: 10.9804\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 524us/step - loss: 10.8790\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 10.9537\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 577us/step - loss: 10.9977\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 590us/step - loss: 10.9021\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 10.9213\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 542us/step - loss: 10.9969\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 11.0790\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 653us/step - loss: 10.8201\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 803us/step - loss: 10.8503 - val_loss: 10.4278\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 745us/step - loss: 10.8306\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 404us/step - loss: 11.0776\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 581us/step - loss: 10.7439\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 521us/step - loss: 10.7786\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 495us/step - loss: 10.9224\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 522us/step - loss: 10.8502\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 11.0579\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 10.7939\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 491us/step - loss: 10.7539\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 928us/step - loss: 10.7310 - val_loss: 10.2906\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.08541497]\n",
      "pretest                                            [0.9441179]\n",
      "school_setting_Rural                               [2.1637654]\n",
      "school_setting_Suburban                            [2.1684196]\n",
      "school_setting_Urban                                 [1.57189]\n",
      "school_type_Non-public                              [2.564338]\n",
      "school_type_Public                                 [1.9474182]\n",
      "teaching_method_Experimental                         [6.18162]\n",
      "teaching_method_Standard                          [0.12113556]\n",
      "gender_Female                                      [2.3985214]\n",
      "gender_Male                                         [2.237892]\n",
      "lunch_Does not qualify                              [2.159622]\n",
      "lunch_Qualifies for reduced/free lunch             [1.5444721]\n",
      "系数b1:[2.6367068]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")#Sequential模型结构 多个网络层且无多余分支的堆叠 Dense就是常用的全连接层 运算就是output = activation(dot(input, kernel)+bias) units为该层的输出维度 而非输入维度  \n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)) #adam（前期降低损失迅速，随迭代次数衰减学习率） 所以可以一开始把学习率提高一点 \n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) #整个数据一共遍历epoch遍 每一次拿batch_size个样本来算损失 所以一个epoch需要算epoch/batch_size遍 更新同样次数的参数\n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094a8c3",
   "metadata": {},
   "source": [
    "换个优化器 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079e56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 733us/step - loss: 510.0822\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 265us/step - loss: 39.8698\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 493us/step - loss: 23.9310\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 509us/step - loss: 21.1697\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 496us/step - loss: 19.3262\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 17.8869\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 494us/step - loss: 16.6689\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 15.7837\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 555us/step - loss: 15.0186\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 14.3578 - val_loss: 14.7016\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 460us/step - loss: 13.8656\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 644us/step - loss: 13.5377\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 537us/step - loss: 13.0737\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 477us/step - loss: 12.9130\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 556us/step - loss: 12.6743\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 585us/step - loss: 12.4461\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 511us/step - loss: 12.4393\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 12.4272\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 684us/step - loss: 12.2872\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.2409 - val_loss: 11.5546\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 603us/step - loss: 12.2126\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 555us/step - loss: 12.1314\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 606us/step - loss: 12.0406\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 541us/step - loss: 12.0123\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 546us/step - loss: 11.9981\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 551us/step - loss: 11.9653\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 11.9441\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.8929\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.8536\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 951us/step - loss: 11.9213 - val_loss: 12.0861\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 490us/step - loss: 11.9008\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 593us/step - loss: 11.8512\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 478us/step - loss: 11.8337\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 11.7480\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 525us/step - loss: 11.8258\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 11.7717\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 570us/step - loss: 11.6813\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 11.7272\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.8192\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 982us/step - loss: 11.6728 - val_loss: 11.4029\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 504us/step - loss: 11.7282\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 626us/step - loss: 11.6739\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 643us/step - loss: 11.6803\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 557us/step - loss: 11.6082\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 499us/step - loss: 11.6620\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 11.5836\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 474us/step - loss: 11.5758\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 11.5607\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 11.5431\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 714us/step - loss: 11.5389 - val_loss: 10.9713\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 796us/step - loss: 11.4239\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 566us/step - loss: 11.4811\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 11.5207\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 471us/step - loss: 11.4079\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 468us/step - loss: 11.5127\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 554us/step - loss: 11.3946\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 551us/step - loss: 11.4086\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 529us/step - loss: 11.3546\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 11.5094\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 873us/step - loss: 11.4008 - val_loss: 10.7579\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 617us/step - loss: 11.4139\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 539us/step - loss: 11.3244\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 531us/step - loss: 11.3870\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 550us/step - loss: 11.3082\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 11.3683\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 11.3102\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 512us/step - loss: 11.2672\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.2910\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 11.3070\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 739us/step - loss: 11.3503 - val_loss: 11.4156\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 904us/step - loss: 11.2349\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 11.2873\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 537us/step - loss: 11.2354\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 11.2096\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 488us/step - loss: 11.2271\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.1851\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 11.1500\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 468us/step - loss: 11.1603\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 555us/step - loss: 11.0612\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1498 - val_loss: 10.6402\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 538us/step - loss: 11.2076\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.1541\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 611us/step - loss: 11.1291\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 611us/step - loss: 11.2261\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 557us/step - loss: 11.1688\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.0863\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 522us/step - loss: 11.0883\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 11.0851\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 474us/step - loss: 11.1965\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 971us/step - loss: 11.1108 - val_loss: 10.7217\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 10.9982\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 593us/step - loss: 10.9789\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.1520\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.0318\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 617us/step - loss: 11.1054\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 595us/step - loss: 11.0913\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 795us/step - loss: 11.0428\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 11.0711\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.0143\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 950us/step - loss: 11.1260 - val_loss: 11.3490\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.20660028]\n",
      "pretest                                            [0.9494998]\n",
      "school_setting_Rural                               [1.9603968]\n",
      "school_setting_Suburban                            [1.7224237]\n",
      "school_setting_Urban                               [1.0075217]\n",
      "school_type_Non-public                             [2.3611765]\n",
      "school_type_Public                                 [1.4294865]\n",
      "teaching_method_Experimental                        [5.040551]\n",
      "teaching_method_Standard                          [-1.0060161]\n",
      "gender_Female                                      [2.2276387]\n",
      "gender_Male                                          [2.08033]\n",
      "lunch_Does not qualify                              [1.867621]\n",
      "lunch_Qualifies for reduced/free lunch             [1.1707518]\n",
      "系数b1:[2.4285486]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.SGD(lr=0.01,clipvalue=0.5))#梯度裁剪 Gradient Clipping +-0.5\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a2a91",
   "metadata": {},
   "source": [
    "自适应梯度 (对初始位置要求很严格 不然直接3000遍历还有1000损失 下降平缓均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bb9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adagrad.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 5831.6851\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 5726.1411\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 494us/step - loss: 5658.4521\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 501us/step - loss: 5604.0244\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 5557.2715\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 5515.9189\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 471us/step - loss: 5478.3857\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 531us/step - loss: 5443.7070\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 495us/step - loss: 5411.4331\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 5381.1001 - val_loss: 4474.4155\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 721us/step - loss: 5352.5005\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 5325.3169\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 678us/step - loss: 5299.3423\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 553us/step - loss: 5274.5186\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 474us/step - loss: 5250.6392\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 5227.6934\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 563us/step - loss: 5205.5039\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 577us/step - loss: 5184.0439\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 5163.3047\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 844us/step - loss: 5143.1104 - val_loss: 4278.0273\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 468us/step - loss: 5123.5107\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 601us/step - loss: 5104.3882\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 552us/step - loss: 5085.7749\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 464us/step - loss: 5067.6304\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 5049.9072\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 5032.5684\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 5015.6104\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 460us/step - loss: 4999.0317\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 4982.7954\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 880us/step - loss: 4966.8589 - val_loss: 4131.3550\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 493us/step - loss: 4951.2026\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 474us/step - loss: 4935.8540\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 517us/step - loss: 4920.7808\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 416us/step - loss: 4905.9170\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 674us/step - loss: 4891.3311\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 570us/step - loss: 4877.0020\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 594us/step - loss: 4862.8779\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 4848.9756\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 4835.3022\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 4821.8208 - val_loss: 4010.3035\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 680us/step - loss: 4808.5366\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 485us/step - loss: 4795.4414\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 507us/step - loss: 4782.5415\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 510us/step - loss: 4769.7778\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 4757.1978\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 531us/step - loss: 4744.8125\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 452us/step - loss: 4732.5620\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 511us/step - loss: 4720.4702\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 4708.5205\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 824us/step - loss: 4696.7144 - val_loss: 3905.7151\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 619us/step - loss: 4685.0581\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 4673.5166\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 4662.1138\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 511us/step - loss: 4650.8389\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 524us/step - loss: 4639.6904\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 471us/step - loss: 4628.6646\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 392us/step - loss: 4617.7534\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 776us/step - loss: 4606.9692\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 4596.2861\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 4585.7114 - val_loss: 3812.8074\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 604us/step - loss: 4575.2373\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 4564.8809\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 513us/step - loss: 4554.5918\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 643us/step - loss: 4544.3984\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 4534.3125\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 691us/step - loss: 4524.3169\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 579us/step - loss: 4514.4146\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 566us/step - loss: 4504.5957\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 562us/step - loss: 4494.8862\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 4485.2505 - val_loss: 3728.6689\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 593us/step - loss: 4475.6919\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 706us/step - loss: 4466.2144\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 4456.8301\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 4447.5161\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 489us/step - loss: 4438.2725\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 500us/step - loss: 4429.1089\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 624us/step - loss: 4420.0186\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 4410.9937\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 624us/step - loss: 4402.0552\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 891us/step - loss: 4393.1880 - val_loss: 3651.5371\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 619us/step - loss: 4384.3794\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 511us/step - loss: 4375.6182\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 4366.9292\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 529us/step - loss: 4358.3301\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 503us/step - loss: 4349.7676\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 591us/step - loss: 4341.2754\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 519us/step - loss: 4332.8521\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 450us/step - loss: 4324.4766\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 554us/step - loss: 4316.1631\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 867us/step - loss: 4307.9170 - val_loss: 3580.0642\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 636us/step - loss: 4299.7153\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 500us/step - loss: 4291.5669\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 4283.4751\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 4275.4419\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 4267.4492\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 510us/step - loss: 4259.5332\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 496us/step - loss: 4251.6494\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 4243.8213\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 469us/step - loss: 4236.0498\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 4228.3311 - val_loss: 3513.3469\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                        [-0.34749752]\n",
      "pretest                                           [0.19079624]\n",
      "school_setting_Rural                              [0.32352412]\n",
      "school_setting_Suburban                           [0.64223295]\n",
      "school_setting_Urban                             [-0.45802018]\n",
      "school_type_Non-public                            [0.35826415]\n",
      "school_type_Public                                [0.50174975]\n",
      "teaching_method_Experimental                      [0.11407156]\n",
      "teaching_method_Standard                          [0.25477195]\n",
      "gender_Female                                     [0.60741085]\n",
      "gender_Male                                       [0.29928836]\n",
      "lunch_Does not qualify                            [0.56092966]\n",
      "lunch_Qualifies for reduced/free lunch           [-0.37562156]\n",
      "系数b1:[0.14127925]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adagrad(lr=0.01,epsilon=1e-6))\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868c0b",
   "metadata": {},
   "source": [
    "结合梯度平方的指数移动平均数来调节学习率的变化。能够在不稳定（Non-Stationary）的目标函数情况下进行很好地收敛。递归神经网络时的一个良好选择？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6285a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 553us/step - loss: 8085.8545\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 531us/step - loss: 7269.1675\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 471us/step - loss: 6520.9087\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 537us/step - loss: 5814.3032\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 512us/step - loss: 5144.4268\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 4522.2173\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 3938.5032\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 3396.8181\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 2898.7349\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 2443.1765 - val_loss: 1317.0623\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 509us/step - loss: 2031.1885\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 615us/step - loss: 1655.3256\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 404us/step - loss: 1325.7626\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 1035.7229\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 643us/step - loss: 789.9135\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 454us/step - loss: 585.2563\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 420.0832\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 518us/step - loss: 295.0756\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 210.0791\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 162.2212 - val_loss: 243.9240\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 706us/step - loss: 140.6117\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 570us/step - loss: 128.9583\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 584us/step - loss: 119.7094\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 596us/step - loss: 111.5803\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 104.0892\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 582us/step - loss: 96.4416\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 89.4118\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 82.7209\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 512us/step - loss: 76.5883\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 919us/step - loss: 70.7526 - val_loss: 129.7521\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 65.2689\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 59.8270\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 54.9932\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 50.3272\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 439us/step - loss: 45.8998\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 456us/step - loss: 41.8235\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 498us/step - loss: 38.0676\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 568us/step - loss: 34.6772\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 31.8260\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 29.3152 - val_loss: 42.6929\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 505us/step - loss: 26.9988\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 586us/step - loss: 25.0395\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 498us/step - loss: 23.1790\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 495us/step - loss: 21.6518\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 478us/step - loss: 20.2958\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 19.0988\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 18.1995\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 590us/step - loss: 17.4932\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 619us/step - loss: 16.9193\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 985us/step - loss: 16.3690 - val_loss: 17.0525\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 620us/step - loss: 15.9276\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 608us/step - loss: 15.5591\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 590us/step - loss: 15.2598\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 14.9795\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 14.7503\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 14.5432\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 589us/step - loss: 14.3469\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 513us/step - loss: 14.1839\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 566us/step - loss: 13.9981\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 953us/step - loss: 13.8990 - val_loss: 12.7122\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 504us/step - loss: 13.7898\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 588us/step - loss: 13.6617\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 462us/step - loss: 13.5584\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 483us/step - loss: 13.4634\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 13.3785\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 455us/step - loss: 13.2750\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 496us/step - loss: 13.1950\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 517us/step - loss: 13.1135\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 501us/step - loss: 13.0225\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 742us/step - loss: 12.9805 - val_loss: 11.7726\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 776us/step - loss: 12.8812\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 510us/step - loss: 12.8260\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 593us/step - loss: 12.8079\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 603us/step - loss: 12.7348\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 518us/step - loss: 12.6819\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 461us/step - loss: 12.6562\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 507us/step - loss: 12.5812\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 540us/step - loss: 12.5649\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 550us/step - loss: 12.5014\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 951us/step - loss: 12.4599 - val_loss: 11.3652\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 12.4441\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 587us/step - loss: 12.3977\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 518us/step - loss: 12.3970\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 504us/step - loss: 12.3450\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 487us/step - loss: 12.3329\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 520us/step - loss: 12.3314\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 12.2808\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 523us/step - loss: 12.2560\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 12.2532\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 948us/step - loss: 12.2223 - val_loss: 11.4158\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 558us/step - loss: 12.1945\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 510us/step - loss: 12.1873\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 12.1528\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 12.1420\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 470us/step - loss: 12.1137\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 487us/step - loss: 12.1105\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 12.0897\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 687us/step - loss: 12.0841\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 699us/step - loss: 12.0430\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 748us/step - loss: 12.0687 - val_loss: 11.2247\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                          [0.4033029]\n",
      "pretest                                            [0.9761519]\n",
      "school_setting_Rural                               [2.1678612]\n",
      "school_setting_Suburban                            [1.3309712]\n",
      "school_setting_Urban                             [-0.09282631]\n",
      "school_type_Non-public                             [2.2431488]\n",
      "school_type_Public                               [-0.03628081]\n",
      "teaching_method_Experimental                       [3.7063093]\n",
      "teaching_method_Standard                          [-1.8566206]\n",
      "gender_Female                                      [0.9322521]\n",
      "gender_Male                                         [0.790686]\n",
      "lunch_Does not qualify                             [1.1137445]\n",
      "lunch_Qualifies for reduced/free lunch             [0.2303096]\n",
      "系数b1:[0.9406519]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-6)) #rho衰减系数 epsilon数值稳定性的小常数？\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d14d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
