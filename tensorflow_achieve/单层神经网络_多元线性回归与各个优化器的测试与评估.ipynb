{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0495bae0-fbd3-4dcc-bb6d-d31c36da394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "from tensorflow import keras # type: ignore\n",
    "import numpy as np  # type: ignore 令人迷惑的在vscode使用jupyternotebook特有的不影响功能的问题\n",
    "import tensorflow as tf\n",
    "from small_functions import print_2d_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "292022a1-4a45-47e7-ad5c-93f938d45ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv(\"data_set/从11个特征预测学生的测试分数.csv\")\n",
    "X , Y = orig_data.iloc[:,0:10] , orig_data.iloc[:,-1] #切片\n",
    "X = X.drop(columns=[\"school\",\"classroom\",\"student_id\"],axis=1)#按列丢弃无关项\n",
    "X = pd.get_dummies(X,columns=[\"school_setting\",\"school_type\",\"teaching_method\",\"gender\",\"lunch\"],dtype=int)#独热编码 #orig_data.iloc[0:5,] X.iloc[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71a365",
   "metadata": {},
   "source": [
    "一层神经网络模型  \n",
    "激活函数f(x)= x  \n",
    "损失函数均方误差  \n",
    "优化器Adam(默认比较优秀的优化器 结合了自适应梯度Adagrad和RMSProp防梯度急剧下降的优点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b907d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 649us/step - loss: 3065.4719\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 506.3102\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 74.8597\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 43.4522\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 518us/step - loss: 40.1849\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 37.3628\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 517us/step - loss: 34.5892\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 510us/step - loss: 31.9350\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 29.4678\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 27.1894 - val_loss: 33.1946\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 576us/step - loss: 25.1153\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 23.2776\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 21.6728\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 20.2570\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 19.0302\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 17.9782\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 17.0617\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 16.2974\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 15.6355\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 15.0742 - val_loss: 14.8605\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 460us/step - loss: 14.6180\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 465us/step - loss: 14.2177\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 576us/step - loss: 13.8988\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 567us/step - loss: 13.5905\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 13.3889\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 737us/step - loss: 13.1880\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 12.9724\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 12.8053\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 12.6623\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 12.5459 - val_loss: 11.7839\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 461us/step - loss: 12.4354\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 461us/step - loss: 12.3413\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 553us/step - loss: 12.3120\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 543us/step - loss: 12.1948\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 12.0960\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 12.0580\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 12.0108\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 570us/step - loss: 11.9050\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 11.9750\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 11.8381 - val_loss: 11.1850\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 461us/step - loss: 11.8223\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.7871\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.7574\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 460us/step - loss: 11.7293\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.7400\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.6854\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.6852\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.6525\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 11.6374\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 11.6130 - val_loss: 11.0022\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 595us/step - loss: 11.5867\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 11.5793\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 568us/step - loss: 11.5622\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 11.5268\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.5431\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.5087\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.5435\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.5054\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.4945\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.4686 - val_loss: 10.9054\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 11.4774\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.4073\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.3749\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.4656\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.3818\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.3414\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.3365\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.3627\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 11.3599\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3520 - val_loss: 11.2007\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 11.3302\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.2734\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.3198\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.2376\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 456us/step - loss: 11.1926\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 471us/step - loss: 11.2119\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 635us/step - loss: 11.2155\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 11.1981\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 570us/step - loss: 11.3544\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.1650 - val_loss: 10.8207\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.2632\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.1806\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 506us/step - loss: 11.2983\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.0998\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 11.1782\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 551us/step - loss: 11.1401\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 456us/step - loss: 11.0390\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.1498\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.1194\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 11.0739 - val_loss: 10.7722\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 11.1243\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.0810\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 11.0347\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 11.0689\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.0177\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 10.9996\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 11.0138\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 589us/step - loss: 10.8988\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 537us/step - loss: 11.0108\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 10.9680 - val_loss: 10.4773\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.14960274]\n",
      "pretest                                            [0.9576854]\n",
      "school_setting_Rural                                [2.194573]\n",
      "school_setting_Suburban                            [1.9425651]\n",
      "school_setting_Urban                               [1.2976052]\n",
      "school_type_Non-public                             [2.7098064]\n",
      "school_type_Public                                 [1.8891464]\n",
      "teaching_method_Experimental                        [5.578539]\n",
      "teaching_method_Standard                          [-0.4387894]\n",
      "gender_Female                                      [1.8820914]\n",
      "gender_Male                                         [1.722551]\n",
      "lunch_Does not qualify                             [1.8636318]\n",
      "lunch_Qualifies for reduced/free lunch             [1.3306768]\n",
      "系数b1:[1.9035074]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")#Sequential模型结构 多个网络层且无多余分支的堆叠 Dense就是常用的全连接层 运算就是output = activation(dot(input, kernel)+bias) units为该层的输出维度 而非输入维度  \n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)) #adam（前期降低损失迅速，随迭代次数衰减学习率） 所以可以一开始把学习率提高一点 \n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) #整个数据一共遍历epoch遍 每一次拿batch_size个样本来算损失 所以一个epoch需要算epoch/batch_size遍 更新同样次数的参数\n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094a8c3",
   "metadata": {},
   "source": [
    "换个优化器 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "079e56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 546us/step - loss: 466.9693\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 509us/step - loss: 44.4441\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 560us/step - loss: 28.8253\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 474us/step - loss: 22.9786\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 476us/step - loss: 19.7565\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 413us/step - loss: 18.0407\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 496us/step - loss: 16.7575\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 463us/step - loss: 15.7532\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 502us/step - loss: 14.9621\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 14.5011 - val_loss: 13.4467\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 492us/step - loss: 13.9711\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 13.5960\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 481us/step - loss: 13.2860\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 460us/step - loss: 13.0148\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 538us/step - loss: 12.8137\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 12.5909\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 512us/step - loss: 12.5080\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 508us/step - loss: 12.3624\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 12.2898\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 944us/step - loss: 12.2477 - val_loss: 11.7915\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 519us/step - loss: 12.2642\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 520us/step - loss: 12.1301\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 12.0770\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 513us/step - loss: 12.0882\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 12.0103\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 11.9951\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 11.9395\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 12.0107\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 531us/step - loss: 11.8718\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 971us/step - loss: 11.8939 - val_loss: 11.5918\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 11.7879\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 655us/step - loss: 11.7923\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 612us/step - loss: 11.8221\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 465us/step - loss: 11.7211\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.7840\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 566us/step - loss: 11.7988\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 520us/step - loss: 11.6813\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.7013\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 568us/step - loss: 11.6444\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 968us/step - loss: 11.8367 - val_loss: 11.3206\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 11.7195\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 541us/step - loss: 11.7577\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 497us/step - loss: 11.6732\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 502us/step - loss: 11.6400\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.5958\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.4966\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 589us/step - loss: 11.5911\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 11.5426\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 11.4724\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 844us/step - loss: 11.4748 - val_loss: 11.5578\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 465us/step - loss: 11.5647\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 11.4407\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 564us/step - loss: 11.5115\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.4574\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 524us/step - loss: 11.4380\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 11.4728\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 456us/step - loss: 11.4129\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.3285\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.3077\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3419 - val_loss: 10.9437\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 507us/step - loss: 11.3852\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 523us/step - loss: 11.3689\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.3572\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.3614\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 459us/step - loss: 11.3360\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 458us/step - loss: 11.3150\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.3284\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 11.2838\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.2137\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 11.2738 - val_loss: 10.9165\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 461us/step - loss: 11.3195\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 492us/step - loss: 11.2095\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 517us/step - loss: 11.3000\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 504us/step - loss: 11.1988\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 525us/step - loss: 11.2427\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 11.1824\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.0489\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 610us/step - loss: 11.1958\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 477us/step - loss: 11.1922\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.1342 - val_loss: 11.5070\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 460us/step - loss: 11.0803\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 456us/step - loss: 11.0940\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 11.0801\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.0771\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.0700\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.1335\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 687us/step - loss: 11.0158\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 455us/step - loss: 11.0615\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.0667\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 11.1396 - val_loss: 10.6465\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 447us/step - loss: 10.9945\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 11.0320\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 11.0094\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 605us/step - loss: 11.0943\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 500us/step - loss: 10.9571\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 10.9498\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 553us/step - loss: 11.0730\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 10.9516\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.0524\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 10.8970 - val_loss: 10.4528\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.15365532]\n",
      "pretest                                           [0.94457626]\n",
      "school_setting_Rural                               [2.3555534]\n",
      "school_setting_Suburban                            [2.1190202]\n",
      "school_setting_Urban                                [1.456918]\n",
      "school_type_Non-public                             [2.3496475]\n",
      "school_type_Public                                 [1.5053698]\n",
      "teaching_method_Experimental                       [5.1955314]\n",
      "teaching_method_Standard                          [-0.8622107]\n",
      "gender_Female                                      [1.9641331]\n",
      "gender_Male                                        [1.8396385]\n",
      "lunch_Does not qualify                             [2.1012347]\n",
      "lunch_Qualifies for reduced/free lunch             [1.4604788]\n",
      "系数b1:[2.3645463]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.SGD(lr=0.01,clipvalue=0.5))#梯度裁剪 Gradient Clipping +-0.5\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a2a91",
   "metadata": {},
   "source": [
    "自适应梯度 (对初始位置要求很严格 不然直接3000遍历还有1000损失 下降平缓均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59bb9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adagrad.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 539us/step - loss: 3602.5652\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 3520.6462\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 3467.9004\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 541us/step - loss: 3425.6863\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 558us/step - loss: 3389.3711\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 486us/step - loss: 3357.3481\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 505us/step - loss: 3328.2747\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 491us/step - loss: 3301.5515\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 3276.7217\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3253.3381 - val_loss: 2474.2014\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 788us/step - loss: 3231.3008\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 438us/step - loss: 3210.3843\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 3190.4431\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 605us/step - loss: 3171.4521\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 501us/step - loss: 3153.1399\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 3135.5142\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 3118.4983\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 457us/step - loss: 3102.0989\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 3086.2122\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 3070.8042 - val_loss: 2330.6873\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 556us/step - loss: 3055.8569\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 558us/step - loss: 3041.2766\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 3027.1211\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 509us/step - loss: 3013.3188\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 2999.8274\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 496us/step - loss: 2986.6768\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 2973.7922\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 2961.2014\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 2948.8857\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 873us/step - loss: 2936.8274 - val_loss: 2224.5718\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 618us/step - loss: 2924.9746\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 2913.3528\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 2901.9441\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 2890.7063\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 570us/step - loss: 2879.6914\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 2868.8743\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 2858.2136\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 2847.7458\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 2837.4485\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 943us/step - loss: 2827.2578 - val_loss: 2137.6230\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 542us/step - loss: 2817.2585\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 571us/step - loss: 2807.4412\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 466us/step - loss: 2797.7339\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 481us/step - loss: 2788.1799\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 230us/step - loss: 2778.7539\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 754us/step - loss: 2769.4270\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 518us/step - loss: 2760.2366\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 506us/step - loss: 2751.1611\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 495us/step - loss: 2742.2087\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 937us/step - loss: 2733.3579 - val_loss: 2063.0552\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 580us/step - loss: 2724.6204\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 2715.9988\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 2707.4624\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 2699.0291\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 2690.7222\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 2682.4902\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 424us/step - loss: 2674.3286\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 2666.2578\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 2658.2693\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 926us/step - loss: 2650.3862 - val_loss: 1997.1576\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 500us/step - loss: 2642.5754\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 531us/step - loss: 2634.8508\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 525us/step - loss: 2627.2012\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 442us/step - loss: 2619.6155\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 502us/step - loss: 2612.1033\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 575us/step - loss: 2604.6768\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 2597.3159\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 584us/step - loss: 2590.0266\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 2582.8171\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 707us/step - loss: 2575.6531 - val_loss: 1937.8213\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 783us/step - loss: 2568.5684\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 613us/step - loss: 2561.5457\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 641us/step - loss: 2554.5984\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 2547.6885\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 2540.8447\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 2534.0688\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 2527.3459\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 2520.6804\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 494us/step - loss: 2514.0820\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 989us/step - loss: 2507.5205 - val_loss: 1883.7397\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 560us/step - loss: 2501.0190\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 569us/step - loss: 2494.5735\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 2488.1782\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 520us/step - loss: 2481.8391\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 535us/step - loss: 2475.5352\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 429us/step - loss: 2469.2827\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 422us/step - loss: 2463.0808\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 478us/step - loss: 2456.9192\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 2450.8210\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 922us/step - loss: 2444.7422 - val_loss: 1833.9244\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 559us/step - loss: 2438.7153\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 552us/step - loss: 2432.7375\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 592us/step - loss: 2426.7939\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 587us/step - loss: 2420.9050\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 2415.0481\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 524us/step - loss: 2409.2307\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 790us/step - loss: 2403.4438\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 2397.6951\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 591us/step - loss: 2392.0027\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 910us/step - loss: 2386.3367 - val_loss: 1787.6140\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                          [0.1939336]\n",
      "pretest                                            [0.2723992]\n",
      "school_setting_Rural                               [0.4160889]\n",
      "school_setting_Suburban                           [0.45945048]\n",
      "school_setting_Urban                              [0.47657245]\n",
      "school_type_Non-public                            [-0.2063928]\n",
      "school_type_Public                                [0.34369722]\n",
      "teaching_method_Experimental                     [-0.11268269]\n",
      "teaching_method_Standard                           [0.5648521]\n",
      "gender_Female                                     [0.68332344]\n",
      "gender_Male                                       [-0.4121814]\n",
      "lunch_Does not qualify                             [0.5826268]\n",
      "lunch_Qualifies for reduced/free lunch            [-0.4280988]\n",
      "系数b1:[0.13976134]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adagrad(lr=0.01,epsilon=1e-6))\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868c0b",
   "metadata": {},
   "source": [
    "结合梯度平方的指数移动平均数来调节学习率的变化。能够在不稳定（Non-Stationary）的目标函数情况下进行很好地收敛。递归神经网络时的一个良好选择？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6285a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 605us/step - loss: 10516.2354\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 302us/step - loss: 9576.8496\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 836us/step - loss: 8701.9951\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 513us/step - loss: 7864.3018\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 580us/step - loss: 7076.9102\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 321us/step - loss: 6331.4673\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 818us/step - loss: 5624.6172\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 573us/step - loss: 4960.7485\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 557us/step - loss: 4338.3154\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 3761.3542 - val_loss: 2748.6848\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 766us/step - loss: 3224.8364\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 577us/step - loss: 2730.5137\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 543us/step - loss: 2279.0012\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 1868.6024\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 534us/step - loss: 1499.8492\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 567us/step - loss: 1173.2621\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 559us/step - loss: 889.4118\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 607us/step - loss: 647.2168\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 444.3747\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 671us/step - loss: 284.4763 - val_loss: 144.7363\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 466us/step - loss: 165.3959\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 502us/step - loss: 85.1876\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 42.8559\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 532us/step - loss: 29.6662\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 27.0122\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 552us/step - loss: 25.3232\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 575us/step - loss: 23.6978\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 490us/step - loss: 22.3103\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 454us/step - loss: 21.0472\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 902us/step - loss: 20.0309 - val_loss: 20.5349\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 560us/step - loss: 19.2179\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 476us/step - loss: 18.4616\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 17.9326\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 477us/step - loss: 17.4313\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 485us/step - loss: 17.0335\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 461us/step - loss: 16.6731\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 16.3321\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 587us/step - loss: 16.0096\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 15.8126\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 979us/step - loss: 15.5744 - val_loss: 15.2577\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 504us/step - loss: 15.3422\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 548us/step - loss: 15.1621\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 513us/step - loss: 14.9598\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 505us/step - loss: 14.7446\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 525us/step - loss: 14.6151\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 574us/step - loss: 14.4055\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 586us/step - loss: 14.3153\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 14.1422\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 484us/step - loss: 13.9673\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 672us/step - loss: 13.8385 - val_loss: 13.3394\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 504us/step - loss: 13.7097\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 587us/step - loss: 13.5955\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 516us/step - loss: 13.4764\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 536us/step - loss: 13.3506\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 515us/step - loss: 13.2320\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 513us/step - loss: 13.1219\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 479us/step - loss: 13.0153\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 441us/step - loss: 12.9136\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 511us/step - loss: 12.8132\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 947us/step - loss: 12.7152 - val_loss: 12.1554\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 608us/step - loss: 12.6458\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 621us/step - loss: 12.5482\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 544us/step - loss: 12.4470\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 557us/step - loss: 12.4069\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 12.3159\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 12.2342\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 12.1727\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 580us/step - loss: 12.1242\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 568us/step - loss: 12.0426\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.0009 - val_loss: 11.3749\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 551us/step - loss: 11.9447\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 572us/step - loss: 11.8970\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 11.8662\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 546us/step - loss: 11.7882\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 616us/step - loss: 11.7736\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 542us/step - loss: 11.7218\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.6705\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 517us/step - loss: 11.6428\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 495us/step - loss: 11.6114\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 780us/step - loss: 11.5652 - val_loss: 10.9960\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 705us/step - loss: 11.5368\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 528us/step - loss: 11.5163\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 514us/step - loss: 11.4853\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 537us/step - loss: 11.4590\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 558us/step - loss: 11.4429\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 529us/step - loss: 11.4203\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 517us/step - loss: 11.3974\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 547us/step - loss: 11.3792\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 499us/step - loss: 11.3592\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 929us/step - loss: 11.3716 - val_loss: 10.8244\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 566us/step - loss: 11.3429\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 549us/step - loss: 11.3250\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 552us/step - loss: 11.3014\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 808us/step - loss: 11.2988\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 576us/step - loss: 11.2840\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 551us/step - loss: 11.2783\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 533us/step - loss: 11.2639\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 527us/step - loss: 11.2375\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 530us/step - loss: 11.2638\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 11.2142 - val_loss: 10.6971\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " IN_PUT (Dense)              (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14 (56.00 Byte)\n",
      "Trainable params: 14 (56.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.22720939]\n",
      "pretest                                           [0.97273016]\n",
      "school_setting_Rural                               [2.0446353]\n",
      "school_setting_Suburban                            [1.4786906]\n",
      "school_setting_Urban                              [0.67459357]\n",
      "school_type_Non-public                             [2.0028331]\n",
      "school_type_Public                                [0.66946125]\n",
      "teaching_method_Experimental                       [4.7967706]\n",
      "teaching_method_Standard                          [-0.6854082]\n",
      "gender_Female                                       [2.078631]\n",
      "gender_Male                                        [1.9606042]\n",
      "lunch_Does not qualify                              [1.275852]\n",
      "lunch_Qualifies for reduced/free lunch              [0.883111]\n",
      "系数b1:[1.5228611]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-6)) #rho衰减系数 epsilon数值稳定性的小常数？\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d14d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
