{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e33c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU set successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 设置GPU设备\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU set successfully!\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f6526",
   "metadata": {},
   "source": [
    "使用gpu训练，看看速度。 tensorflow2.6.0 keras2.6.0  CUDAv12.8 cudnn-windows-x86_64-8.9.7.29_cuda12-archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292022a1-4a45-47e7-ad5c-93f938d45ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_student</th>\n",
       "      <th>pretest</th>\n",
       "      <th>school_setting_Rural</th>\n",
       "      <th>school_setting_Suburban</th>\n",
       "      <th>school_setting_Urban</th>\n",
       "      <th>school_type_Non-public</th>\n",
       "      <th>school_type_Public</th>\n",
       "      <th>teaching_method_Experimental</th>\n",
       "      <th>teaching_method_Standard</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>lunch_Does not qualify</th>\n",
       "      <th>lunch_Qualifies for reduced/free lunch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>30.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_student  pretest  school_setting_Rural  school_setting_Suburban  \\\n",
       "0          20.0     62.0                     0                        0   \n",
       "1          20.0     66.0                     0                        0   \n",
       "2          20.0     64.0                     0                        0   \n",
       "3          20.0     61.0                     0                        0   \n",
       "4          20.0     64.0                     0                        0   \n",
       "...         ...      ...                   ...                      ...   \n",
       "2128       30.0     39.0                     0                        0   \n",
       "2129       30.0     38.0                     0                        0   \n",
       "2130       30.0     45.0                     0                        0   \n",
       "2131       30.0     46.0                     0                        0   \n",
       "2132       30.0     41.0                     0                        0   \n",
       "\n",
       "      school_setting_Urban  school_type_Non-public  school_type_Public  \\\n",
       "0                        1                       1                   0   \n",
       "1                        1                       1                   0   \n",
       "2                        1                       1                   0   \n",
       "3                        1                       1                   0   \n",
       "4                        1                       1                   0   \n",
       "...                    ...                     ...                 ...   \n",
       "2128                     1                       0                   1   \n",
       "2129                     1                       0                   1   \n",
       "2130                     1                       0                   1   \n",
       "2131                     1                       0                   1   \n",
       "2132                     1                       0                   1   \n",
       "\n",
       "      teaching_method_Experimental  teaching_method_Standard  gender_Female  \\\n",
       "0                                0                         1              1   \n",
       "1                                0                         1              1   \n",
       "2                                0                         1              0   \n",
       "3                                0                         1              1   \n",
       "4                                0                         1              0   \n",
       "...                            ...                       ...            ...   \n",
       "2128                             0                         1              1   \n",
       "2129                             0                         1              1   \n",
       "2130                             0                         1              1   \n",
       "2131                             0                         1              0   \n",
       "2132                             0                         1              0   \n",
       "\n",
       "      gender_Male  lunch_Does not qualify  \\\n",
       "0               0                       1   \n",
       "1               0                       1   \n",
       "2               1                       1   \n",
       "3               0                       1   \n",
       "4               1                       1   \n",
       "...           ...                     ...   \n",
       "2128            0                       1   \n",
       "2129            0                       0   \n",
       "2130            0                       0   \n",
       "2131            1                       0   \n",
       "2132            1                       0   \n",
       "\n",
       "      lunch_Qualifies for reduced/free lunch  \n",
       "0                                          0  \n",
       "1                                          0  \n",
       "2                                          0  \n",
       "3                                          0  \n",
       "4                                          0  \n",
       "...                                      ...  \n",
       "2128                                       0  \n",
       "2129                                       1  \n",
       "2130                                       1  \n",
       "2131                                       1  \n",
       "2132                                       1  \n",
       "\n",
       "[2133 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data = pd.read_csv(\"data_set/从11个特征预测学生的测试分数.csv\")\n",
    "X , Y = orig_data.iloc[:,0:10] , orig_data.iloc[:,-1] #切片\n",
    "X = X.drop(columns=[\"school\",\"classroom\",\"student_id\"],axis=1)#按列丢弃无关项\n",
    "X = pd.get_dummies(X,columns=[\"school_setting\",\"school_type\",\"teaching_method\",\"gender\",\"lunch\"],dtype=int)#独热编码 #orig_data.iloc[0:5,] X.iloc[0:5,]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71a365",
   "metadata": {},
   "source": [
    "一层神经网络模型  \n",
    "激活函数f(x)= x  \n",
    "损失函数均方误差  \n",
    "优化器Adam(默认比较优秀的优化器 结合了自适应梯度Adagrad和RMSProp防梯度急剧下降的优点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b907d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 979us/step - loss: 2543.8308\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 345.0066\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 826us/step - loss: 52.8748\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 903us/step - loss: 37.7791\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 35.1561\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 32.6324\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 30.1926\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 983us/step - loss: 27.8799\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 979us/step - loss: 25.7364\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 23.8201 - val_loss: 26.1615\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 773us/step - loss: 22.0880\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 841us/step - loss: 20.5833\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 796us/step - loss: 19.2784\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 921us/step - loss: 18.1536\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 17.1482\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 16.3206\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 782us/step - loss: 15.6367\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 963us/step - loss: 15.0614\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 742us/step - loss: 14.5846\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 14.1645 - val_loss: 12.9727\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 762us/step - loss: 13.8182\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 987us/step - loss: 13.5165\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 997us/step - loss: 13.2665\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 13.0733\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.8928\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.7361\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 752us/step - loss: 12.5892\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 839us/step - loss: 12.5255\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 728us/step - loss: 12.3644\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.2629 - val_loss: 11.3107\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 814us/step - loss: 12.1892\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.1427\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.0421\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 983us/step - loss: 12.0440\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 970us/step - loss: 12.0216\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.9399\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 935us/step - loss: 11.8889\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 875us/step - loss: 11.8277\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 850us/step - loss: 11.8277\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.7626 - val_loss: 11.2222\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.7750\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 883us/step - loss: 11.6951\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 862us/step - loss: 11.7174\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 11.6838\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 739us/step - loss: 11.6491\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 11.6459\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 920us/step - loss: 11.6231\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 957us/step - loss: 11.5991\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.6113\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5355 - val_loss: 10.9321\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 934us/step - loss: 11.5412\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 994us/step - loss: 11.5537\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 704us/step - loss: 11.5203\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 967us/step - loss: 11.5541\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5084\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.4888\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 970us/step - loss: 11.4696\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 11.4426\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 859us/step - loss: 11.3973\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3934 - val_loss: 11.1880\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 862us/step - loss: 11.3710\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 11.3859\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 846us/step - loss: 11.4180\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 728us/step - loss: 11.4001\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 955us/step - loss: 11.3387\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 839us/step - loss: 11.3059\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.2743\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 735us/step - loss: 11.3826\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 943us/step - loss: 11.2826\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2837 - val_loss: 11.6610\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 11.2796\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 782us/step - loss: 11.2441\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 933us/step - loss: 11.2317\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 958us/step - loss: 11.1781\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 870us/step - loss: 11.1658\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1381\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1622\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2785\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 858us/step - loss: 11.1476\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1444 - val_loss: 10.8041\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 839us/step - loss: 11.1118\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1336\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 795us/step - loss: 11.0659\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 923us/step - loss: 11.0981\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 868us/step - loss: 11.0023\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 958us/step - loss: 11.0034\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 956us/step - loss: 11.1716\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 11.0421\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 726us/step - loss: 10.9958\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9948 - val_loss: 10.7638\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 846us/step - loss: 10.9748\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 778us/step - loss: 11.0693\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 877us/step - loss: 10.9458\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 895us/step - loss: 10.9498\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 742us/step - loss: 10.8957\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 710us/step - loss: 10.8842\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 818us/step - loss: 10.9102\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.8388\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 10.8823\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8869 - val_loss: 12.0959\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.15041369]\n",
      "pretest                                           [0.96634734]\n",
      "school_setting_Rural                               [2.0517159]\n",
      "school_setting_Suburban                            [1.9187467]\n",
      "school_setting_Urban                               [1.2817979]\n",
      "school_type_Non-public                             [2.8331866]\n",
      "school_type_Public                                   [2.05803]\n",
      "teaching_method_Experimental                       [5.3917313]\n",
      "teaching_method_Standard                           [-0.647374]\n",
      "gender_Female                                      [2.1231868]\n",
      "gender_Male                                        [1.9932166]\n",
      "lunch_Does not qualify                             [2.3095348]\n",
      "lunch_Qualifies for reduced/free lunch             [1.7374976]\n",
      "系数b1:[1.9130298]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")#Sequential模型结构 多个网络层且无多余分支的堆叠 Dense就是常用的全连接层 运算就是output = activation(dot(input, kernel)+bias) units为该层的输出维度 而非输入维度  \n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)) #adam（前期降低损失迅速，随迭代次数衰减学习率）学习率提高一点 \n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) #整个数据一共遍历epoch遍 每一次拿batch_size个样本来算损失 所以一个epoch需要算epoch/batch_size遍 更新同样次数的参数\n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094a8c3",
   "metadata": {},
   "source": [
    "换个优化器 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079e56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 859us/step - loss: 2203.6917\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 785us/step - loss: 601.6945\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 879us/step - loss: 42.1208\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 781us/step - loss: 19.1598\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 803us/step - loss: 17.7152\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 745us/step - loss: 16.2958\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 810us/step - loss: 15.2241\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 786us/step - loss: 14.4278\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 925us/step - loss: 13.8414\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 13.3639 - val_loss: 12.6784\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 905us/step - loss: 12.9375\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 852us/step - loss: 12.7686\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 792us/step - loss: 12.5456\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 796us/step - loss: 12.1884\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 924us/step - loss: 12.1236\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 802us/step - loss: 11.9883\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 804us/step - loss: 11.9988\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 811us/step - loss: 11.8791\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 11.8652\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.8308 - val_loss: 11.0519\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.8848\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 909us/step - loss: 11.8443\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 798us/step - loss: 11.7043\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 686us/step - loss: 11.8304\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 802us/step - loss: 11.7363\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 796us/step - loss: 11.7280\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.7114\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 881us/step - loss: 11.6469\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 796us/step - loss: 11.5590\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5896 - val_loss: 11.0597\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5353\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 11.6076\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 924us/step - loss: 11.5948\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 11.5008\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 799us/step - loss: 11.4440\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 804us/step - loss: 11.5406\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.5842\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.4548\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 905us/step - loss: 11.4181\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.3762 - val_loss: 10.9306\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 800us/step - loss: 11.3914\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 11.3916\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 11.4416\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 804us/step - loss: 11.3339\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 895us/step - loss: 11.3195\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 892us/step - loss: 11.2449\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 802us/step - loss: 11.5103\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 11.5344\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 11.3050\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2504 - val_loss: 10.8428\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 765us/step - loss: 11.2565\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 11.1339\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 797us/step - loss: 11.2586\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 719us/step - loss: 11.2111\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 785us/step - loss: 11.1763\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 810us/step - loss: 11.2406\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 907us/step - loss: 11.1578\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1959\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 795us/step - loss: 11.2506\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1196 - val_loss: 11.2593\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 11.0927\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 919us/step - loss: 11.0913\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 11.1447\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 880us/step - loss: 11.0603\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 828us/step - loss: 11.0619\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 817us/step - loss: 11.1959\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 814us/step - loss: 11.0993\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 805us/step - loss: 11.1674\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 827us/step - loss: 11.1619\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1082 - val_loss: 11.5968\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 829us/step - loss: 11.1153\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 833us/step - loss: 11.0642\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 780us/step - loss: 11.0335\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 880us/step - loss: 11.1002\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 845us/step - loss: 11.1927\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 694us/step - loss: 11.0777\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 714us/step - loss: 10.9697\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 901us/step - loss: 11.1156\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 750us/step - loss: 10.9890\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0197 - val_loss: 10.8981\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.9643\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 795us/step - loss: 10.9534\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 822us/step - loss: 10.9803\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 819us/step - loss: 11.0639\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9432\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 857us/step - loss: 10.8998\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 833us/step - loss: 10.9403\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 842us/step - loss: 10.9965\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 832us/step - loss: 10.9931\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9092 - val_loss: 11.2260\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 743us/step - loss: 10.9592\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 784us/step - loss: 10.9606\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 763us/step - loss: 10.8816\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 751us/step - loss: 10.9190\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 732us/step - loss: 10.8980\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 754us/step - loss: 10.9029\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 842us/step - loss: 10.8780\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 750us/step - loss: 10.8804\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 763us/step - loss: 10.9378\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8244 - val_loss: 10.4814\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                          [0.1333781]\n",
      "pretest                                           [0.94544595]\n",
      "school_setting_Rural                               [2.2557878]\n",
      "school_setting_Suburban                             [2.125178]\n",
      "school_setting_Urban                               [1.4633446]\n",
      "school_type_Non-public                             [2.1666696]\n",
      "school_type_Public                                 [1.4095467]\n",
      "teaching_method_Experimental                       [5.4129086]\n",
      "teaching_method_Standard                         [-0.62538975]\n",
      "gender_Female                                      [2.1816015]\n",
      "gender_Male                                        [2.0756886]\n",
      "lunch_Does not qualify                             [2.4574885]\n",
      "lunch_Qualifies for reduced/free lunch             [1.8713583]\n",
      "系数b1:[2.618988]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.SGD(learning_rate=0.01,clipvalue=0.5))#梯度裁剪 Gradient Clipping +-0.5\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a2a91",
   "metadata": {},
   "source": [
    "自适应梯度 (对初始位置要求很严格 不然直接3000遍历还有1000损失 下降平缓均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bb9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 795us/step - loss: 1656.7402\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 809us/step - loss: 1177.4430\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 791us/step - loss: 927.8684\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 906us/step - loss: 757.2111\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 881us/step - loss: 630.1652\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 804us/step - loss: 531.1011\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 452.0047\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 387.5287\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 797us/step - loss: 334.1453\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 289.6642 - val_loss: 213.3415\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 770us/step - loss: 252.3220\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 723us/step - loss: 220.6066\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 764us/step - loss: 193.7391\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 745us/step - loss: 170.7055\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 701us/step - loss: 151.0027\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 680us/step - loss: 134.0661\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 793us/step - loss: 119.5037\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 782us/step - loss: 106.9521\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 684us/step - loss: 96.0750\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 86.6649 - val_loss: 64.6640\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 803us/step - loss: 78.5271\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 770us/step - loss: 71.4722\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 698us/step - loss: 65.3327\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 681us/step - loss: 59.9839\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 713us/step - loss: 55.3399\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 702us/step - loss: 51.3016\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 717us/step - loss: 47.7598\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 863us/step - loss: 44.6904\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 717us/step - loss: 41.9983\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 39.6684 - val_loss: 32.3581\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 775us/step - loss: 37.6323\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 793us/step - loss: 35.8718\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 713us/step - loss: 34.3102\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 723us/step - loss: 32.9619\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 698us/step - loss: 31.7788\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 717us/step - loss: 30.7269\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 748us/step - loss: 29.8115\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 932us/step - loss: 29.0222\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 721us/step - loss: 28.3197\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 27.7162 - val_loss: 25.2113\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 27.1780\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 827us/step - loss: 26.7004\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 725us/step - loss: 26.2839\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 774us/step - loss: 25.9157\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 698us/step - loss: 25.5918\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 781us/step - loss: 25.2996\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 712us/step - loss: 25.0499\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 848us/step - loss: 24.8283\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 775us/step - loss: 24.6309\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 24.4525 - val_loss: 23.7175\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 760us/step - loss: 24.2926\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 735us/step - loss: 24.1497\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 710us/step - loss: 24.0245\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 718us/step - loss: 23.9107\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 717us/step - loss: 23.8098\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 685us/step - loss: 23.7201\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 748us/step - loss: 23.6373\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 731us/step - loss: 23.5625\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 748us/step - loss: 23.4932\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 23.4302 - val_loss: 23.3951\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 938us/step - loss: 23.3728\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 974us/step - loss: 23.3183\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 996us/step - loss: 23.2706\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 973us/step - loss: 23.2241\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 23.1787\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 23.1363\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 858us/step - loss: 23.0968\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 708us/step - loss: 23.0599\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 737us/step - loss: 23.0248\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.9906 - val_loss: 23.2344\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 746us/step - loss: 22.9582\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 566us/step - loss: 22.9271\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 879us/step - loss: 22.8960\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 755us/step - loss: 22.8665\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 755us/step - loss: 22.8383\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 922us/step - loss: 22.8106\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 22.7831\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.7561\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 905us/step - loss: 22.7300\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.7039 - val_loss: 23.0543\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 735us/step - loss: 22.6789\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 775us/step - loss: 22.6551\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 805us/step - loss: 22.6306\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 22.6063\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 22.5821\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.5580\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.5345\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.5107\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 814us/step - loss: 22.4873\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.4637 - val_loss: 22.8423\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.4413\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 813us/step - loss: 22.4180\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 798us/step - loss: 22.3957\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 684us/step - loss: 22.3733\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 804us/step - loss: 22.3512\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 859us/step - loss: 22.3284\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 694us/step - loss: 22.3064\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 787us/step - loss: 22.2844\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 832us/step - loss: 22.2623\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 22.2405 - val_loss: 22.6090\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                         [0.43929562]\n",
      "pretest                                           [0.97977954]\n",
      "school_setting_Rural                              [0.81975335]\n",
      "school_setting_Suburban                           [0.44209674]\n",
      "school_setting_Urban                              [0.23567733]\n",
      "school_type_Non-public                             [0.9114183]\n",
      "school_type_Public                                [0.38097614]\n",
      "teaching_method_Experimental                       [0.6575708]\n",
      "teaching_method_Standard                          [0.66794616]\n",
      "gender_Female                                      [0.8018549]\n",
      "gender_Male                                       [0.77455324]\n",
      "lunch_Does not qualify                             [0.6340417]\n",
      "lunch_Qualifies for reduced/free lunch           [-0.05927514]\n",
      "系数b1:[0.55055314]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.Adagrad(learning_rate=0.01,epsilon=1e-6))\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868c0b",
   "metadata": {},
   "source": [
    "结合梯度平方的指数移动平均数来调节学习率的变化。能够在不稳定（Non-Stationary）的目标函数情况下进行很好地收敛。递归神经网络时的一个良好选择？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6285a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 909us/step - loss: 6842.5713\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1720.3939\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 941us/step - loss: 134.9007\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 30.0543\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 910us/step - loss: 18.1644\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 943us/step - loss: 15.1702\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 13.7345\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 12.8666\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 12.3767\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 12.1782 - val_loss: 11.1597\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.8809\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 11.8719\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 976us/step - loss: 11.7221\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 883us/step - loss: 11.6302\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.6389\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 904us/step - loss: 11.7285\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.6576\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 11.6251\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5182\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.5087 - val_loss: 10.8454\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.3935\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.4830\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 804us/step - loss: 11.3276\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.3265\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 921us/step - loss: 11.3106\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 11.3168\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.2902\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1867\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 907us/step - loss: 11.3682\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2538 - val_loss: 17.2480\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 977us/step - loss: 11.2393\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.2044\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 866us/step - loss: 11.0322\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 11.0940\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 920us/step - loss: 11.2048\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 919us/step - loss: 11.1392\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 11.1282\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 11.2647\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.9606\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0018 - val_loss: 10.3004\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.1153\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0457\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 838us/step - loss: 11.0297\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 912us/step - loss: 10.9912\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 949us/step - loss: 10.9755\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 911us/step - loss: 11.0000\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 949us/step - loss: 11.0290\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 797us/step - loss: 10.9808\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 952us/step - loss: 10.8992\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 11.0925 - val_loss: 11.5930\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 10.9687\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 11.0766\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 972us/step - loss: 10.9326\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 10.9320\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 10.9174\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8118\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 930us/step - loss: 10.8161\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 897us/step - loss: 10.8354\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 10.8189\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9706 - val_loss: 10.9177\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7449\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8130\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7987\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 10.8377\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.9472\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.7953\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 10.8792\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8345\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 917us/step - loss: 10.8259\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7677 - val_loss: 11.5089\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 916us/step - loss: 10.8309\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 10.8097\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8306\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 990us/step - loss: 10.7690\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 955us/step - loss: 10.8946\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 805us/step - loss: 10.8389\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 804us/step - loss: 10.8682\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 992us/step - loss: 10.8419\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8816\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7911 - val_loss: 10.1151\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.7467\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.7737\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 10.8899\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7066\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 989us/step - loss: 10.9228\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 930us/step - loss: 10.7503\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 993us/step - loss: 10.7949\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 943us/step - loss: 10.6492\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 962us/step - loss: 10.7700\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8358 - val_loss: 12.1697\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7046\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.9427\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.8305\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7338\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 10.8715\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 801us/step - loss: 10.8289\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 10.6810\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 10.8401\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 919us/step - loss: 10.7572\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 10.7662 - val_loss: 9.9894\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "IN_PUT (Dense)               (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "特征对应相关的系数w1如下:\n",
      "n_student                                        [-0.01617224]\n",
      "pretest                                           [0.92471737]\n",
      "school_setting_Rural                               [2.9449186]\n",
      "school_setting_Suburban                            [3.3249526]\n",
      "school_setting_Urban                                [2.810354]\n",
      "school_type_Non-public                              [2.886659]\n",
      "school_type_Public                                  [2.629016]\n",
      "teaching_method_Experimental                        [5.947548]\n",
      "teaching_method_Standard                         [-0.15885961]\n",
      "gender_Female                                      [2.9730356]\n",
      "gender_Male                                        [2.8314142]\n",
      "lunch_Does not qualify                              [2.764787]\n",
      "lunch_Qualifies for reduced/free lunch             [2.0114257]\n",
      "系数b1:[3.446868]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=1,activation='linear',name = 'IN_PUT',input_shape=(13,)),\n",
    "     ]\n",
    ")\n",
    "model.compile(loss = keras.losses.MeanSquaredError(),optimizer = keras.optimizers.RMSprop(learning_rate=0.01, rho=0.9, epsilon=1e-6)) #rho衰减系数 epsilon数值稳定性的小常数？\n",
    "model.fit(X,Y,epochs=100,validation_split=0.2,validation_freq=10,batch_size=32) \n",
    "model.summary() \n",
    "w1,b1 = model.get_layer(\"IN_PUT\").get_weights()\n",
    "print(\"特征对应相关的系数w1如下:\")\n",
    "for i in range(len(X.columns)):\n",
    "    print(\"{:<40}  {:>20}\".format(str(X.columns[i]),str(w1[i])))\n",
    "print(\"系数b1:{}\".format(str(b1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
